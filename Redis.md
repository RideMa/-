## Redis
* redis是内存数据存储引擎，可以用作数据库、缓存、消息队列和分布式锁等
* redis有String、Hash、Set、Zset、Bitmap、Hyperloglog、GEO、Stream
* 数据操作是原子性的
* redis支持事务、持久化、Lua脚本、多种集群方式、发布/订阅模式、内存淘汰机制、过期删除机制等等
### Redis和Memcache有什么区别
* 都是高性能内存数据库，一般用来做缓存，都有过期替换策略
* Redis数据结构更丰富，Memcache只有key-value
* Redis支持持久化，Memcache断电就没了
* Redis支持集群化，Memcache依靠客户端实现往集群里写入数据
* Redis支持订阅模型、Lua脚本、事务等
### Redis作为MySQL的缓存
* MySQL QPS很难突破1w，Redis可以轻松突破10w
* 请求从Redis读取数据，没有再从MySQL加载数据到Redis
* 缓存一致性问题通过先修改，再删除，部分解决
### Redis数据类型的应用场景
* String：缓存对象、常规计数、分布式锁、共享session信息等
* List：消息队列（生产者需要自行实现全局唯一ID、不能以消费组的形式消费数据）
* Set：聚合计算的场景，比如点赞、关注、抽奖活动等
* Zset：排序场景，排行榜、热搜、电话和姓名排序等
* Bitmap：二值状态统计的场景、用户登录状态、签到、连续签到的人数
* HyperLoglog：海量数据统计、百万级网页uv计数
* GEO：LBS
* Stream：消息队列，相比List，自动生成全局唯一ID，可以用消费组的形式消费数据
### Redis数据类型的实现
* String基于SDS
* * 动态简单字符串，不仅可以保存文本还可以保存二进制
* * 获取字符串长度的代价是O（1）
* * SDS API是安全的，拼接字符串不会造成缓冲区溢出
* List基于双向链表或压缩列表
* * 小于512个，列表每个元素的值都小于64字节，使用压缩列表
* * 其他使用双向链表
* * redis3.2之后List底层都是quicklist实现的
* Hash是压缩列表或哈希表
* * 哈希类型元素小于512个，每个都小于64字节，使用压缩列表
* * 其他用哈希表
* * redis 7.0之后压缩列表被listpack取代了
* Set是压缩列表或跳表
* * 元素个数小于128个，每个都小于64字节，用压缩列表
* * 其他用跳表
* * 7.0以后压缩列表被listpack取代
* Zset用压缩列表或跳表
* * 和Set一样
* GEO用ZSET实现
* Bitmap
* HyperLogLog
* Stream
### Redis线程模型
* Redis单线程指的是接受客户端请求、解析请求、进行数据读写操作、发送数据到客户端时主线程完成的
* redis会启动后台进行，2.6以前俩，处理关闭文件、AOF刷盘；4.0之后加了一个，lazyfree异步释放Redis内存
* 删除大key的时候，使用del命令会使得主线程阻塞，要用unlink
* 主线程会把BIO_CLOSE_FILE队列放要关闭的任务，BIO_AOF_FSYNC放要AOF刷盘的任务，BIO_LAZY_FREE放要释放内存的任务，后台线程从队列里面取出任务，进行处理
* 主线程再6.0以前的模型：
* * 注册I/O多路复用epoll，把socket都注册进去
* * epoll_wait等待，发现任务以后进行分发
* * 连接事件用accept，再注册socket
* * 读事件用read，解析命令、执行命令、添加到发送队列，执行结果加入缓存
* * 写事件，调用write，如果一轮没法玩，注册一个写事件函数到epoll，epoll发现可以写的时候下一轮接着发（每次循环都会写，处理epoll发现的事件后要写一轮）
* Redis使用单线程模型是因为CPU不是Redis性能表现的瓶颈所在，更多情况受内存和网络I/O的限制
* 并且可维护性高，多线程可能增加程序复杂性、同时存在线程切换、加锁、解锁等带来的性能损耗
* Redis6.0之后的多线程模型
* * 采用多个I/O线程处理网络请求，因为网络I/O硬件设备的提升使得其瓶颈可能再网络I/O上
* * 可以将I/O性能提高1倍以上
* * 推荐4核CPU，2-3个I/O线程（主线程也算）
* * redis 6.0之后默认额外开启6个线程，前三个一样：关闭文件、AOF刷盘、Lazyfree，还有三个io_thd分担网络I/O压力
### Redis为什么这么快
* redis都在内存中完成，采用了高效的数据模型
* redis使用单线程模型，避免了多线程之间的竞争，省去了线程切换的时间和性能开销
* redis使用I/O多路复用机制处理大量的socket，
### Redis持久化
* AOF日志
* * 每执行一次写操作之后，就把命令以追加的方式写入一个文件里
* * \*3的意思是命令有3个部分，$3是这个部分有几个字符
* * 先执行命令再写入日志到数据库
* * * 这样可以避免额外的检查开销，如果是错的就不用写日志了
* * * 不会阻塞当前的写操作
* * * 但是数据可能会丢失（写日志之前断电）
* * * 可能阻塞其他操作（主线程写AOF文件，还是会阻塞后续操作）
* * AOF写操作有三种写回策略
* * * always：总是，每次操作之后都刷盘
* * * everysec，每秒把写命令输刷盘
* * * No，redis不管，操作系统决定啥时候刷盘
* * AOF重写
* * * 如果AOF文件太大了，就会重写
* * * 读取每一个键值对，把其写为一个AOF命令，用新的代替旧的文件
* * * 使用后台子进程bgrewriteaof来实现，这样可以不用阻塞主进程
* * * 子进程有数据副本，并且由于cow，父子进程数据安全，其副本不会变，父进程还可以继续操作
* * * 主进程执行期间的把命令写道AOF缓冲区，并且写到AOF重写缓冲区
* * * 完事了把新的覆盖旧的就行了（期间还是要写旧的，防止失败）
* RDB快照
* * 把某一时刻的内存数据以二进制写入磁盘
* * 有save和bgsave，前者阻塞，后者不阻塞
* * 可以用命令save num1 num2来定期执行，num1秒内对数据库至少进行了num2次修改就快照
* * 子进程进行RDB的时候还是可以操作的
* 混合持久化
* * 再AOF文件重写的时候，fork的子进程会先RDB写入AOF文件，然后主线程处理的操作命令会被记录再重写缓冲区，写完以后以增量的形式写在AOF后面
* * 之后AOF文件就变成了前一部分是RDB，后面是AOF
* * 优点：可以结合RDB的优点，快速启动，又可以结合AOF有点，丢失少
* * 缺点：AOF文件加入了RDB可读性差，兼容不了redis4.0之前的版本
### Redis集群
* redis主从复制
* * 主服务器可以读写，从服务器只有读取，
* * 由于从服务器复制过程是异步的，因此不是强一致性
* 哨兵模式
* * 哨兵可以监控主从节点的故障，从而控制其故障转移
* 切片模式
* * 一个服务器无法处理，就用多个服务器，对数据库进行切片
* * redis cluster方案中，一个切片集群有16538个哈希槽
* * 根据key得到一个hash值，然后模16538，得到映射
* * 哈希槽的分配可以是平均或者手动指定等
* 脑裂
* * 主节点和哨兵失联，哨兵认为其挂了，新指定一个节点
* * 但是主节点还是可以更客户端通信，于是还在读写
* * 这时候新选了一个主节点，就有俩主节点了
* * 这样重新连回来的时候就会把数据覆盖掉了
* * 解决方法：必须有至少x个从节点可以通信才写数据，t时间内必须有x个回信
* * 没法完全解决，需要抽屉原理才行
### Redis过期删除策略
* Redis过期删除策略和内存淘汰策略是不一样的
* * 过期删除是对于一个key，可以设置一个过期时间，过期的key需要删除
* * 过期字典是一个哈希表
* * 删除策略是Redis会把带有过期时间的key放在过期字典里，惰性删除加定期删除
* * * 惰性删除就是访问的时候再查看key是否在过期字典里，如果在就看是否过期，如果过期了就删除
* * * 惰性删除的优势是CPU友好，不需要定期轮询，只有访问的时候才检查
* * * 缺点是对内存不友好，如果一个key过期了又一直不访问，就一直在内存里，占内存
* * 定期删除是每隔一段时间随机从数据库中取出一定数量的key，删除其中过期的
* * * 具体是从过期字典里随机抽取20个，删除过期的key，如果过期的key大于5个（25%）就继续抽20个
* * * 优势是可以删除过期的不被访问的key，同时通过随机20个，可以减少操作对CPU的影响
* * * 缺点是难以确定具体的时间长度和频率，如果时间长了，占内存，时间短了占CPU
* * * redis每秒进行10次定期删除，10Hz
* * * 定期删除循环不超过25ms，防止循环过度线程卡死
* 持久化时过期键
* * RDB文件生成的时候会看是否过期，过期的不生成
* * RDB文件读取的时候看是不是主服务器，主服务器会判断，从服务器不会，不过主从复制的时候从服务器会清空数据
* * AOF文件持久化的时候如果过期了，AOF还会持有，删除的时候会在后面追加一个DEL
* * AOF重写阶段不会写入过期的键
* 主从模式对过期键的处理
* * 从库不处理，依靠主库的AOF文件
### Redis内存淘汰策略
* redis最大内存在redis.conf里通过maxmemory设置，64位默认是0，不限制，32位默认是3G（交给操作系统来限制内存）
* noeviction 3.0之后的默认模式，不会淘汰内存
* volatile-random 随机淘汰设置了过期时间的任意键
* volatile-ttl 优先淘汰更快过期的键
* volatile-lru 淘汰所有设置了过期时间的键里最久未使用的 3.0之前默认
* volatile-lfu 淘汰所有设置了过期时间的键中使用次数最少得，4.0之后新增
* allkeys-random 所有键随机
* allkeys-lru 所有键最久未使用
* allkeys-lfu 所有键最少使用次数
* LRU问题：链表数据空间的占用，数据被访问的时候需要移动链表，性能占用
* Redis LRU算法，是给每个对象结构体加上了一个最后访问时间，内存淘汰的时候随机访问5个，淘汰最久未使用的那个
* LRU无法解决缓存污染的问题，一下读了太多数据，这些数据在内部停留很久
* Redis中，LRU算法下对象头的24bits是用来记录key访问时间戳的
* LFU算法下，对象头24bits分成两个部分，前16bits是访问时间戳，后8bits是访问次数
* 访问字数不是单纯的访问次数，而是访问频次，logc会随着时间而衰减
* 每次访问key的时候会先做一个衰减运算，衰减值跟前后访问时间差有关系，差值越大衰减值越大
* 衰减之后会增加，增加也是根据概率增加的，logc越大的key，logc越难增加
* lfu-decay-time控制衰减，越大越慢，lfu-log-factor越大增长越慢
### Redis缓存设计
* 缓存雪崩
* 如果有大量请求没有命中，到达后端数据库，会导致数据库压力骤增，严重的会宕机形成一系列连锁反应，造成整个系统崩溃
* 原因可能是：大量的key同时过期，热点数据过期（缓存击穿），大量不存在的key访问（缓存穿透）
* 解决方案：
* * 设置在过期时间上加上一个随机偏移量，或者设置成不过期
* * 对于缓存击穿，可以使用互斥锁方案，保障只有一个业务线程请求后端资源，其他阻塞；或者热点数据不过期，后台定期更新；或者热点数据快过期了就通知后台数据更新缓存，更新过期时间
* * 对于缓存击穿，可以在API入口处限制判断缓存请求参数是否合理，发现有穿透的现象给其加一个空值，利用布隆过滤器快速判断是否数据不存在
* 动态缓存热点数据策略
* * 通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。
* * 利用Zset构建排序队列，根据访问时间更新队列信息，越近访问越靠前
* * 系统定期过滤掉最后两百个商品，再从数据库随机读200个
* * 每次请求到达的时候先从队列里获取商品ID，如果命中根据ID从另一个缓存结构读取实际商品信息
* * Redis可以用zadd或者zrange完成排序队列和获取200个商品的操作
* 缓存更新策略
* * cache aside
* * * 读：没有就从数据库读，更新缓存
* * * 写：先写数据库，再删缓存
* * * 适合读多写少，无法保证缓存一致性
* * * 如果先删缓存，再更新数据库，可能会再删除缓存之后，更新数据库之前读到旧值，更新缓存，导致不一致
* * * 先改后删也有可能，可能读到旧值，更新数据库，删除缓存，然后又旧值写回缓存
* * * lease的使用方式：
* * * 1. 缓存miss就给分配一个lease，如果数据被删除，那么lease也失效，这样就不会不一致了。因为后续写入或被阻止
* * * 2. 惊群，热门key的写入会导致缓存大量不命中（缓存穿透），每个key 10秒一个lease，拿到的可以和数据库要数据，其他的只能等着或者拿过期数据
* * write through
* * * 用户只和缓存打交道
* * * 读：没有就缓存自己从数据库读，更新缓存
* * * 写：改缓存，缓存写数据库
* * * 双写一致性，redis和memcache没有和数据库打交道的功能
* * write back
* * * 读：没有就从数据库读，更新缓存
* * * 写：改缓存，标记为脏
* * * 分布式场景没法用
### Redis实现延迟队列
* 利用Zset
* Zset的Score设定成时间，然后通过Zadd加入内存生产消息
* 在利用zrangebyscore查询符合条件的所有待处理任务，通过循环执行任务即可
### Redis大key如何处理
* 大key是value大的key
* string类型值大于10kb，或其他的大于5000个
* 大key的问题
* * 客户端超时阻塞，也能为处理大key费时间
* * 引发网络阻塞，流量太大，大key带来大流量
* * 阻塞工作线程，del大key会阻塞
* * 内存分布不均，集群模式在slot分片下，出现数据和查询倾斜问题
* 找大key的方法
* * redis-cli --bigkeys，在从节点上好，因为会阻塞，只能返回每种类型最大的key，对于集合类型只统计个数，不统计真实大小
* * 使用SCAN命令
* * * 对于string直接用STRLEN
* * * 对于集合类型，如果知道平均大小（业务层面），知道集合个数就行了，LLEN、HLEN、SCARD、ZCARD
* * * 不知道的话用MEMORY USAGE，查询键值对的内存空间（4.0版本）
* * 用rdbtools查询，通过解析redis rdb文件来找
* 删除大key的方法
* * 删除需要释放内存，一下释放太多会让空闲内存链表操作很久，导致主线程阻塞
* * 分批次删除：
* * * 对于HASH，用hscan，每次获取100个，然后hdel删除1个
* * * 对于LIST，用ltrim每次少删一点
* * * 对于大SET，用sscan，每次srem一个键
* * * 对于大ZSET，zremrangebyrank，每次删除一部分
* * 异步删除
* * * 用unlink来代替del
* * * 开启lazyfree-lazy-(eviction, expire, server-del, flush)机制，对于内存满了、过期了、server处理已存在的键、从节点复制，不是del而是lazyfree
### Redis管道有什么用
* 客户端批处理技术，一次处理多个redis命令
* 解决多个命令执行时的网络等待和redis没啥关系
### Redis事务支持回滚吗
* 没有回滚机制
* DISCARD是放弃事务，把暂存的命令队列清空
* redis并不一定保证原子性
* 作者认为这种错误大多是编程错误，支持回滚性能代价太大了
### Redis怎么实现分布式锁
* set命令的NX参数，表示KEY不存在才插入
* 加上EX PX可以表示过期时间
* 锁需要区分不同客户端，因此需要设置一个unique_value来标识客户端
* SET lock_key unique_value NX PX 10000 
* 解锁就是del lock_key，需要保证是加锁的客户端
* 可以用Lua脚本保障解锁的原子性，只有value满足才解锁
* 优点：
* * 性能高效
* * 实现方便
* * 避免单点故障
* 缺点
* * 超时时间不好设置：太长了影响性能，太短了事务还没执行完
* * * 合理的设置时间：给锁设置一个守护线程，当快过期了，续约，主线程结束了销毁就行
* * 主从复制时异步的，导致分布式锁不太可靠
* * * 如果主节点宕机了，从节点也没同步到锁，那就有两个客户端能获得锁了
* redis解决集群模式下分布式锁的可靠性问题
* Redlock，官方推荐至少5个主节点，互不相关
* 客户端与这些节点分别要锁，只要大于一半就成功了
* 首先获取时间t1，然后向N个节点加锁，需要设置等待超时时间
* 一旦获得了一半以上N/2 + 1个节点的锁，计算一个当前时间t2
* 如果t2-t1大于锁的过期时间，就加锁成功
* 