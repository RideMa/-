## 面试准备
* MySQL
* Redis
* Linux
* 计网
* WebServer

### 数据结构
* 两个栈实现队列
* * 每次入队进一个栈
* * 每次出队看另一个栈是否为空，如果空把入栈的栈导到另一个空的，弹出栈底，把空栈设为入栈的栈；如果不为空，那么直接弹出栈顶
* * 并发情况？必须加锁
* 哈希表，哈希散列冲突，如何解决？
* * 开放寻址法（往后找个空的，好多方法找，主要是删的时候不能真正删，得打标记，下一个元素插入才能删）
* * 链
* * rehash
* * 公共溢出区
* 二叉搜索树、AVL、红黑树
* * 二叉搜索树退化成链表
* * AVL旋转太慢，记不住旋转，红黑树也记不住
* * 红黑树，保障最长路径不超过最短路径的两倍
* * 节点为红或者黑，根为黑，叶子结点（空的）为黑
* * 红节点的子节点为黑，红节点的父节点为黑，从根到叶子结点没有两个连续的红
* * 任意节点到叶节点的所有路径包括相同数目的黑
* * 红黑树和4阶B树有等价性，黑节点与红子节点融合为一个B树节点，
* B树、B+树
* R树、R+树
* 跳表skiplist，随机插入层数来维护
* 一致性散列
* 排序算法：冒泡、插入、快排、归并、桶排序等
* 小顶堆，小顶堆
* * 堆是完全二叉树，因此可以用数组表示
* * 大顶堆：每个节点都大于等于左右孩子，小顶堆，每个节点都小于等于左右孩子
* * 大顶堆：a[i] >= a[2i+1] && a[i] >= a[2i+2]
* * 小顶堆：a[i] <= a[2i+1] && a[i] <= a[2i+2]
* * 堆排序，构成一个大顶堆，然后最大值就是根节点，将其与末尾元素互换，此时末尾就是最大值，然后对n-1个元素重新构成一个堆，重复执行
* * 建堆的时候首先找到最后一个非叶节点，序号为length/2-1
* * 如果其左子结点大于它，那么就交换它和它的左子结点，然后查看它的左子树是否满足堆结构，如果不满足就要重新调整子树结构
* * 然后右子节点，右子树，然后找下一个非叶节点，也就是当前下标-1，重复过程直到建堆完成（一直减1）
* * 插入是放最后，然后调整；删除是删根，然后把最后一个放在根，然后调整
* 线段树（区间问题常用，最长上升自区间，），字典树（查找的，统计词频，内存展开了贼大， 前缀树过滤敏感词）
* 一个生产者，一个消费者，用循环队列做缓冲区，需要用锁实现同步吗？
* * 不需要直接用缓冲区读就行了
* 快速排序
* * 也是交换排序，但是每次选一个数，把大于它的和小于它的放在两边
```Golang
func quickSort(arr []int) []int {
    return _quickSort(arr, 0, len(arr)-1)
}

func _quickSort(arr []int, left, right int) []int {
    if left < right {
        partitionIndex := partition(arr, left, right)
        _quickSort(arr, left, partitionIndex-1)
        _quickSort(arr, partitionIndex+1, right)
    }
    return arr
}

func partition(arr []int, left, right int) int {
    pivot := left
    index := pivot + 1
	// 单指针定位
    for i := index; i <= right; i++ {
        if arr[i] < arr[pivot] {
        	// 以基准值作为交换参考，将所有小于基准值的数前移，
            swap(arr, i, index)
            // 索引
            index += 1
        }
    }
    // 将基准值调整到它最终要到的有序目标位置
    // 达到区间内基准值左侧比它小右边比它大,实现双指值双向移动的效果
    swap(arr, pivot, index-1)
    return index - 1
}

func swap(arr []int, i, j int) {
    arr[i], arr[j] = arr[j], arr[i]
}

```
* * 实现方法
* * * house：p从左、q从右，p碰到比选的数大就停下，q碰到比选的数小就停下，交换，直到pq相遇，和选择数交换
* * * 挖坑法：保存第一个数，从后找比第一个小的，放到第一个，从前找比第一个大的，放到最后一个，不断循环
* * * 快慢指针：快指针小于key，则交换快慢指针，并且让慢指针向前走
* * * 还可以实现栈的：把区间用两个数表示，入栈，每次出栈一个区间，化为左右区间入栈，直到不能
* * 快速排序的最好时间复杂度和最坏时间复杂度分别是多少
* * 最好O(nlogn)最坏O(n^2)，正序或倒序
* 归并排序
```Golang
package main

import (
	"fmt"
)
func mergeSort(nums []int) []int {
	if len(nums) < 2{
		// 分治，两两拆分，一直拆到基础元素才向上递归。
		return nums
	}
	i := len(nums) / 2
	left := mergeSort(nums[0:i])
	// 左侧数据递归拆分
	right := mergeSort(nums[i:])
	// 右侧数据递归拆分
	result := merge(left, right)
	// 排序 & 合并
	return result
}

func merge(left, right []int) []int {
	result := make([]int, 0)
	i, j := 0, 0
	l, r := len(left), len(right)
	for i<l && j<r{
		if left[i] > right[j]{
			result = append(result, right[j])
			j++
		}else {
			result = append(result, left[i])
			i++
		}
	}
	result = append(result, right[j:]...)
	result = append(result, left[i:]...)
	return result
}

func main() {
	arr := []int{8, 9, 5, 7, 1, 2, 5, 7, 6, 3, 5, 4, 8, 1, 8, 5, 3, 5, 8, 4}
	result := mergeSortgiao(arr)
	fmt.Println(result)
}

```
### 操作系统
* 进程和线程区别，协程
* 一个进程最多能创建多少个线程？
* 进程间通信方式
* 线程通信方式
* 线程安全，多线程并发控制
* linux常用命令：df，du，top，grep，telnet，curl，wget，netstat，sar，ls，cat，tail，
* linux文件权限
* SSH修改默认端口号
* 查看文件最后100行的命令，tail -n 100 my.log
* 进程I/O控制方法：阻塞、非阻塞、同步、异步
* I/O多路复用：select，poll，epoll
* 线程池
* 共享内存的函数：shmget,shmat,shmdt,shmctl
* * ipcrm -m id可以删除
* 死锁产生的机制，如何在项目中排查死锁，如何解决死锁
* LRU算法：Hashmap+双向链表
* * 双向链表建立起来以后保存在hashmap里，这样查询就是O(1)
* * 删除和插入的时候，删除可以通过hashmap找到双向链表的节点，然后根据前后指针就能删掉了，插入就放最后
* * 更新的时候和也是，插入和删除记得更新hashmap
* Buff都有过期时间，设计一个高效的管理器（Linux系统的timer）
* * 暂时不会
* 乐观锁和悲观锁
* * CAS是乐观锁
* 内存页面置换
* * 
* 软件中断和硬件中断的处理流程
* * 
* lazy alloc
* * 缺页中断
* 内核有哪几个子系统
* * 虚拟内存（内存管理），进程管理，进程通信，文件系统，网络系统
* 内存页为什么要设置成4kb
* * 磁盘扇区读取，太大了太小了

### 计算机网络
* TCP三次握手：两次行吗？四次行吗？
* TCP四次挥手：为什么要有time wait？
* TCP具体字段
* 从输入url到页面显示的过程
* 在网络层或者在应用层实现可靠数据传输
* RPC和HTTP的优劣
* 常用的RPC框架，thrift，gRPC
* 负载均衡（不同层级，DNS，反向代理，IP，MAC地址，软件硬件）
* ngnix，ngnix为什么要有分发，跨域是谁控制的
* http和https的区别，https为什么安全
* TLS四次握手，内涵与算法
* 对称加密和非对称加密
* 对于一个银行取钱的业务，如何在传输层保障数据安全？请你设计流程？
* 对于传输层你设计的这个流程，是否需要设计应用层的安全保障机制？
* 假设当前我使用一个app看视频，使用了那些协议？
* 假如我要设计一个手机黑名单，我要用那种数据结构？
* 什么是tcp粘包，为什么会粘包？
* 在进行压测的时候用的是长连接还是短连接？HTTP长连接和短连接的应用场景？
* HTTP状态码
* session和cookie的关系和区别
* WebSocket和HTTP的关系
* HTTP Get一定没有Body吗？Post一定有Body吗？
* HTTP2.0和1.0的区别
* RequestBody和RequestParam区别
* DNS查询，递归查询和迭代查询

### 数据库
* 库存扣减
* InnoDB的锁问题，索引结构
* 聚簇索引
* InnoDB事务隔离级别
* 幻读、脏读，不可重复读
* SQL：limit后面加两个数字的含义
* 视图
* 索引是不是越多越好
* SQL语句执行顺序
* SQL语句优化
* mysql执行计划，慢查询日志
* MySQL给一些离散度较低的字段建立索引会出现什么问题？
* redo log undo log区别
* MySQL联合索引失效的场景
* MySQL的索引数据结构介绍
* GUID和UUID作为关键的索引会出现什么现象？
* 场景题：如何建表，建表需要考虑哪些问题
* MySQL为什么是B+树
* 什么是最左匹配原则，距离说明是否用到了联合索引
* 如何检查慢查询并优化
* 数据库多条件查询
* MySQL左查询和右查询的区别
* MySQL的分页
* 联合索引如果查询第一列中的"%a"可以吗
* 数据库的持久性如何实现
* SQL 选出每个用户的最近访问时间
* mysql乐观锁和悲观锁
* 左连接、右连接、全连接那个快，什么场景用

### 分布式系统
* 分布式锁：zookeeper，Redis
* 分布式事务：2PC，Seeta，3PC，TCC
* 分布式事务的使用场景和实现方式
* 分布式事务如何通过消息队列来实现不同节点之间的事务协调和数据交互
* 脑裂
* 缓存一致性
* redis缓存雪崩，缓存击穿，缓存穿透，解决办法？
* redis主从复制
* redis数据结构
* redis+lua库存扣减
* redis+lua的原子性
* redis set指令
* redis rehash
* redis 延时队列
* redis 集群模式
* redis key过期策略
* redis 缓存删除策略
* redis 内存淘汰机制
* redis 的持久化机制 数据类型
* Redis 持久性，RDB方式为什么fork一个子进程就不阻塞主进程了？（COW）
* Redis AOF缓存区 刷盘时机？如果交给操作系统，操作系统如何决定什么时候刷盘？
* Redis 压缩列表缺点？ 为了能够倒序遍历，entry里的长度记录的是前一个entry的长度。
* Redis 字符串怎么扩容的？
* Redis IO多路复用机制了解吗？
* redis 一致性哈希如何用？怎么判断slot属于哪一个节点，初始化怎么分配slot？
* redis 日志框架 日志级别
* redis 哨兵
* MySQL的缓存和redis的缓存有什么区别
* 分布式分库分表
* 如何保证缓存和数据库数据的一致性？
* MQ如何保障消息不丢失？如何保证消息的顺序性？
* MQ怎么确定生产者确实发布了消息，消费者确实收到了消息
* rocketmq的特性，怎么支持重试，生产者消费者模式
* rabbitmq消息堆积，高并发？
* Kafka怎么保证消息不丢失
* Kafka消息消费幂等性
* 集群环境怎么更新本地缓存？
* 什么时候用到缓存，Redis和Memcache的区别，各自使用的场景
* 微服务用过哪些？
* es怎么用的


### Golang
* go语言协程的实现机制，为什么要用协程，什么是GMP模型
* * go关键字会产生一个Goroutine，其实是一个用户态线程，用户态线程没有时钟中断，就不会强制退出，因此看起来是在协作，也就是协程
* * 用户态线程保存栈和寄存器，使用ucontext来实现的协程，协程创建默认2KB
* * Golang在运行的时候有一个调度器，用GMP模型调度所有的Goroutine，其非Goroutine分配时间，将操作系统线程和逻辑处理器绑定，在逻辑处理器上运行Goroutine，调度器在任何给定时间都会全面控制goroutine要在哪个逻辑处理器上运行
* * G：goroutine，M：内核态线程，P：逻辑处理器
* * P最多GOMAXPROCS个，初始化保存在一个数组里，默认是CPU数；这也意味着同一时刻最多GOMACPROCS个G在运行
* * M最大默认是10000个，一个M阻塞了会创建新的M
* * 基本运行方式是，M获取一个P，然后从P的本地队列里拿G运行，运行一会以后把G放到P的末尾，然后再从P里拿一个，如果没有了就从Global里拿，如果没有就从别的P那里拿一半过来，如果还没有就进入线程池休眠
* * P会周期性查看Global里是否有G等待调度到M里
* * 当G阻塞系统调用的时候，M将会释放P，进而某个空闲的M1会获得P，继续执行P队列剩下的G
* * M带着G系统调用完了，如果有空闲的P，就进队，继续执行，没有就进Global，M进线程池睡眠
* * 当G执行channel读写、网络poll、定时器等操作的时候，会把G设置为WAITING状态，不再运行，当有结果了以后，对应的G放在全局队列里
* * Golang提供的网络接口是阻塞调用，但是底层是epoll的非阻塞I/O，会放到wait里去，epoll有结果了在唤醒，放global里
* * 一个G运行了很久，会被打标记，执行函数调用的时候会被抢掉（最多10ms）
* * 线程复用：work steal 没活干了不是销毁，而是别的地方找任务；hand out 当绑定的线程因为系统调用阻塞了，就释放，把P给别的空闲的M执行
* * 由于局部性原理，G1创建的G2会放在同一个P里，调度的时候，G1先让出P，然后G0（schedule）到P里做调度，让G2接着被M带着运行
* go管道底层是怎么实现的，有缓冲管道和无缓冲管道
* * Go有经常被使用的设计模式是不要通过共享内存的方式通信，CSP模型
* * channel是一个管道型的解决方案，但是其实也是基于内存的通信，不过不需要像管道那样进入内核态，只要在用户态就可以完成
* * 
* * channel底层是一个环形队列，结构体
```go
type hchan struct {
    qcount uint // 队列中的总元素个数
    dataqsiz uint // 环形队列大小，即可存放元素的个数
    buf unsafe.Pointer // 环形队列指针
    elemsize uint16 //每个元素的大小
    closed uint32 //标识关闭状态
    elemtype *_type // 元素类型
    sendx uint // 发送索引，元素写入时存放到队列中的位置

    recvx uint // 接收索引，元素从队列的该位置读出
    recvq waitq // 等待读消息的goroutine队列
    sendq waitq // 等待写消息的goroutine队列
    lock mutex //互斥锁，chan不允许并发读写
}
```
* * channel中读数据
* * 1. 如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒
* * 2. 如果等待发送队列不为空，则缓冲区已满，从缓冲区首部读出数据，把G中数据写入缓冲区尾部，把G唤醒
* * 3. 如果缓冲区有数据，则从缓冲区取出数据，结束读取。将当前goroutine放入recvq，进入睡眠，等待被写goroutine唤醒
* * channel中写数据
* * 1. 如果等待接收队列recvq不为空，则缓冲区为空或者没有缓冲区，直接从recvq中取出G，把数据写入，唤醒G
* * 2. 缓冲区有空余位置，写入缓冲区
* * 3. 缓冲区没有空余位置，则将发送数据写入G，将当前G加入sendq，进入睡眠，等待唤醒
* * 关闭channel
* * * 会将recvq中的所有G唤醒，本该写入G的数据位置为nil
* * * 将sendq中所有G唤醒，但是这些G会panic
* * nil的channel读写都会阻塞住，一般用在select里，就不会到达这个分支了
* 无缓冲的管道在没有接受者条件下能正常接受数据吗
* * 会阻塞，死锁
* 管道关闭了写数据会咋样
* * 我的经历是会报错，panic，程序退出
* * 读取的时候还可以读到，或者nil
* context的作用，结构的原理
* * 可以控制一组树状结构的Goroutine，每个goroutine有相同的上下文，是并发安全的，控制多个协程之间的协作、取消操作
```go
type Context interface {
    Deadline() (deadline time.Time, ok bool)
    Done() <-chan struct{}
    Err() error
    Value(key interface{}) interface{}
}
```
* * Deadline方法，可以获取截止时间，到了这个时间，context就会发起取消请求，返回值ok表示是否设置了截止时间
* * Done方法返回一个只读chan，如果可以读取，表示发出了取消信号，可以做清理操作，然后退出协程，释放资源
* * Err返回Context被取消的原因，Value方法获取Context上绑定的值，是一个键值对
* * background和TODO可以创建Context，前者一般是所有的父亲，后者是避免参数为nil
* * context可以派生context，然后以第一个参数的形式传递，从而可以在后续的goroutine里跟踪超时、跟踪数值
* * 当超时发生时，派生的所有context都会取消，或者取消调用后，也会取消所有子context，调用Done就发现能读到东西，就取消了
* * 控制超时可以节省资源，其实就是拥有同样上下文的一组Goroutine可以被同时取消掉
* * valueCTX没有子节点信息，只有一个父节点，可以网上找value
* * 上游可以取消下游任务，下游不会影响上游
* * 上游是通知下游可以取消了，下游可以自行决定是否取消
* waitgroup实现
* * 源码很简单
```go
type WaitGroup struct {
	noCopy noCopy
	state1 [3]uint32
}
```
* * noCopy表示不可复制，传递的时候只能传指针
* * state1包含counter总数、waiter等待数、sema信号量
* * add的时候给counter加1，done给counter减1，counter的时候唤醒waiter数量的goroutine
* * ADD的实现就是给counter加1，然后看是否counter是0，如果是，就唤醒wait，done就是ADD(-1)
* * wait的实现就是看counter是不是0，如果是就不用等了，否则给wait加1，阻塞等待唤醒
* select怎么用
```go
select {
	case <- chan1:
		// 如果 chan1 成功读到数据，则进行该 case 处理语句
	case chan2 <- 1:
		// 如果成功向 chan2 写入数据，则进行该 case 处理语句
	default:
		// 如果上面都没有成功，则进入default处理流程
}
```
* * 如果都没成功也没有default就阻塞
* * select可以控制超时（和<-context.Done()组合），或者到一定时间给某个chan写一个数，或者使用time.After(...)
* * 具体实现原理是每个case是一个结构体，保存在一个数组里，select执行一个函数，锁定所有channel，如果有ready的就执行
* * 如果都没ready也没default，就把当前协程放到所有channel的等待队列，唤醒后对应进行读写操作
* Gin
* * 是一个go的web框架，类似于flask，性能高效
* defer和return
* * return是两步，给返回值赋值、然后执行ret
* * defer在两者之间，
* * 两个defer会先执行后面的
* * 如果返回值是命名的，那么defer会改变那个返回值，也就会影响了
* * 即使panic，也会执行defer的东西，因此，如果在defer中执行recover捕获了异常，也就不会panic了
* slice和map底层实现
* * slice底层是一个指针，一个len和一个capcity，指针指向一个数组
* * map底层是两个buckets列表，每个列表元素是一个链表的头部，根据hash值来找slot，然后再放到链表里
* * slice扩容策略：
* * 1. 如果新的容量大于原来的两倍，那就是新的容量
* * 2. 如果旧的长度小于1024，那就翻倍
* * 3. 如果旧的长度大于等于1024那就是原来的1.25倍
* * 4. 如果计算出来的cap溢出了，那最终计算出来的cap就是新容量
* * 如果扩容到了原来的数组上，那就容易出bug
* * 如果没有超过cap，就不会重新分配内存
* * slice分配内存和垃圾回收是最大的挑战，拷贝内存问题不大，如果频繁修改用list会比较好，list是双向链表（我咋感觉不对）
* * map有两个buckets，发生扩容的时候记录扩容前的buckets数组指针
* * map是hmap，指向buckets，buckets是bmap，一个buckets里有若干个bmaps（2^B，取hash值的后B位作为桶的标识）
* * 一个bmap指向8个keyvalue对，如果超过了8个，就用overflow指向下一个bmap
* * bmap会维护一个tophash即高8位，意思是如果高8位都不满足，那肯定不满足
* * map扩容有两种，等量扩容和2倍扩容
* * 等量扩容就是由于删删改改，可能有空洞，不换桶，就把桶内的空洞补一补，也是要搬到新的里面去的！
* * 两倍扩容的时候可能会换桶，桶的数量变化，B+1.那么多取一位hash，如果是0就不变，如果是1，就放到新的桶里去
* * 扩容条件：装载因子=map中元素个数/当前的桶个数，即每个桶平均个数
* * 如果装载因子大于6.5就要扩容，或者B小于15，overflow的buckets数超过2^B，或者B>=15，overflow的bucket数大于2^15
* * 对于前一个条件，B+1也就是2倍扩容即可，对于后一个条件，等量扩容即可
* * 扩容的时候不是一下搬完，每次更新插入和删除都只移动两个Bucket
* * math.NaN()每次计算结果都不一样，按照tophash的最后一位判断在新的桶还是旧的桶
* slice和map是线程安全的吗
* * 都不是线程安全的
* * map并发写入的时候会直接panic，要写的时候需要加Mutex锁
* map的元素为什么不能取地址
* * 因为扩容之后位置可能就变了，通过unsafe得到的地址不能长期持有
* go语言什么数据类型可以比较
* * 浮点、字符串、布尔、复数、指针、chan（同一个make，或都nil）、数组
* * 结构体也可以比较，前提是字段都可以比较，并且类型、个数、顺序一致
* * 接口是靠结构体实现的，所以比较就是结构体比较
* * nil可能不相等，因为类型可能不一样
* * slice、map、function不可比较，但是可以和nil比较
* * nil的slice和空的slice不一样
* new和make的区别
* * new返回的是指针，make是值类型
* * make只能slice、chan、map
* * new会把分配的内存区域清零，make会初始化
* 垃圾回收原理
* * go自带垃圾回收，也就是清除不可达对象
* * v1.3之前是暂停业务逻辑，标记不可达、标记完了开始清除，然后再跑
* * 三色标记法
* * 新创建的对象默认是白色，每次GC回收的时候都会从根节点开始遍历对象，放入灰色集合，遍历灰色对象，把灰色对象引用的放入灰色，自己进入黑色，直到没有灰色，回收白色
* * 不采用STW保护，会出现白色对象被黑色对象引用，灰色对象与它之间的可达关系的白色对象遭到破坏
* * 强三色不等式：强制不允许黑色对象引用白色对象
* * 弱三色不等式：黑色对象可以引用白色，如果白色对象有其他链路被灰色对象引用
* * 插入屏障：A对象引用B对象的时候B对象变为灰色，只有堆上的对象需要屏障，栈上不触发，因为清除的时候要重新扫描一遍栈
* * 问题：最后还要STW扫描栈
* * 删除屏障：被删除的对象，如果自身位灰色或白色，则被标记为灰色
* * 问题：精度低，一个被删除的对象，指向它的指针下一轮才会被删除
* * Go V1.8之后是三色标记法+混合写屏障机制
* * 1. 开始把栈上对象全标记为黑色
* * 2. GC期间，在栈上新建的对象都是黑色
* * 3. 被删除和添加的对象标记为灰色
* * GO的GC为每个P都分配了gcMarker，有的P在回收，有的P在继续运行用户协程
* * 如果P没事干，也偷不到东西，就执行gcMarker
* * GC出发模式
* * 1. 辅助模式，堆内存到了上次GC的两倍，启动新一轮GC
* * 2. 调用runtime.GC阻塞启动一轮GC
* * 3. sysmon是运行时守护协程，超过runtime.forcegcperiod，默认2分钟没执行GC就来一轮
* * GOGC参数来调节，表示GC触发时占用内存的比例，0-100
* * Java是代际的，不同生命周期长度在不同的区域，不同区域不同算法
* Go语言有什么优势，为什么选择go，和Java，C++的区别
* * Golang天然支持高并发，其非常适合网络编程，goroutine调度利用多核性能，效率很高
* * Go是比较常用的工程语言，有强大的标准库，并且效率很高
* * Go比C/C++更稳定，其内存管理更加智能，开发效率高，部署方便，跨平台方便（不用cgo）
* Go为什么天然支持高并发
* * goroutine，GMP
* Go的继承和多态
* * 继承就是struct里有父类
```go
type Student struct {
    Name string     //姓名
    Age int         //年龄
    Score int   //成绩
}

type Pupil struct {
    Student
}

type Graduate struct {
    Student
}
```
* * 多态是interface实现的
* * 也就是说子类可以分别实现一个接口，然后调用的时候用接口的var来调用，就是不同的函数
* Go强类型、弱类型
* * 强类型，主要是强类型少隐式转换，弱类型会隐式转换
* Go内存管理模型
* * 采用Google的TCMalloc算法
* * 每个线程维护一个独立的内存池，内存分配的时候从内存池里分配，内存池不够了才加锁，向全局内存池申请，减少系统调用的损耗
* * 内存切的非常细，分为多级管理，降低锁的粒度
* * 回收对象不是释放内存，先放到大块内存里，空闲内存多了才释放
* * mspan是内存管理的基本单元，每个mspan管理一个8KB的页，Go有68种大小的spanClass，用于小对象的分配
* * 大于32K的对象会从堆里分配，一个特殊的span
* * mcache，每个P都有一个，mheap是唯一的，
* * Go的微对象、小对象、大对象
* * * 微对象小于16B，先线程缓存微分配器，然后线程缓存、中心缓存、堆
* * * 小对象16B到32k，先线程缓存，再中心缓存，再堆
* * * 大对象大于32K，直接堆
* * 内存碎片处理算法，为什么有stop the world，刚开始是全部STW，后来三色标记法是最后扫描栈和清理的时候STW，后面是只有打开写屏障的时候STW。主要是不STW的话，就会破坏强三色不等式
* Sync.map为什么线程安全
* * 性能比map加sync.Mutex好，比加读写锁也好得多
* * 里面有一个read_map和一个dirty_map
* * 读的时候从read_map里读，读到了就ok，没读到就要看dirty_map和read_map是否有差异，如果有就要锁住整个map，然后去读，发现read_map没读到，但是dirty_map读到了，就要记录一个miss
* * miss多了就把dirty_map升级成read_map
* * 更新操作
* * 1. 存储过程遵循互不影响的原则，如果在read map中读到，就只更新readmap，否则只更新dirtymap
* * 2. 优先从readmap读，更新失败才读dirtymap
* * 3. 存储新的值，如果readmap有，dirtymap没有，就要刷一遍dirtymap
* * 删除操作直接删除read_map的值
* * 无论存储还是读取，read map的值肯定能在dirtymap中找到
* * 当存储新值时，一定发生在dirty map中，当读取旧值时，如果read map读到就返回，否则加锁去dirty读，因此读多写少很合适
* Sync.Mutex实现原理
* * 主要是信号量PV操作，借助了atomic
* * 一个状态一个信号量用来唤醒goroutine
* * 状态分为四个部分，等待者数量，是否有唤醒的，饥饿模式、锁定否
* * 正常模式等待着FIFO，但是第一个被唤醒的可能争不过正在运行的
* * 饥饿模式直接递交给第一个等待的，新来的不会自旋，直接排在最后
* * 正常模式性能好，但是饥饿模式可以避免病态情况的尾部延迟
* * 加锁分为三种情况，无冲突，CAS加锁；有冲突，开始自旋，没成功就调用semrelease，进入等待状态
* unsafe是啥
* * 可以做指针类型转换，直接转不行的
* * 比如把slice底下的数组转成指针
* * unsafe的指针还能搞运算，转成uintptr，算完再转回来
* * sizeOf、Alignof、Offsetof用来获取大小、对齐、偏移
* * 本来指针不能运算，不能转换，不能比较，unsafe在源码里很多
* 原子操作，atomic
* * 依赖硬件指令，并且需要运行时调度器配合
* * 函数被编译器专门编译成使用CPU指令进行
* * 原子值修改的时候Goroutine不应该抢占，需要锁定MP的绑定关系
* Go内存逃逸，竞态
* * 竞态就是用-race参数可以看到是否存在资源竞争，用锁可以隔离
* * 局部变量会放在栈上，函数结束后其作用域就结束了，但是如果在函数运行结束后还想用，就叫内存逃逸，Go会分析是否函数结束后还用，如果还用就放到堆上，就叫内存逃逸
* * 如果函数外部存在引用，那么就肯定放堆里，栈放不下也放堆里
* * 内存逃逸的场景，内存逃逸在编译阶段完成
* * 返回对象的指针引用
* * 栈放不下了
* * 变量大小在编译的时候无法确定
* * interface表示不同的类型，就会逃逸
* * 闭包引用对象
* Golang传参
* * 是值传递，不过map、slice、chan、interface都是默认以引用的方式i传递
* * 但是如果map、slice重新改变了内存位置，那就没法改变原来的了
* 空struct{}不占空间，rune是UTF-8字符，相当于int32
* Golang对齐，32位4字节，64位8字节
* * 结构体成员变量偏移量必须是成员大小整数倍
* * 整个结构体地址必须是最大字节的整数倍
* Go设计模式
* * 设计模式的基础是多态
* * 好多啊，也不太会
* * 创建型模式
* * * 单例模式：一个类只有一个实体，并提供一个访问它的全局接口，小写类名首字母，Once方法实现
* * * 简单工厂模式：专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类
* * * 工厂方法模式：定义一个创建产品对象的工厂接口，将实际创建工作推迟到子类中
* * * 抽象工厂模式：提供创建一系列相关或相互依赖的接口，而无需指定他们具体的类
* * * 原型模式：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象
* * * 建造者模式：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示
* * 结构型模式
* * * 适配器模式：将一个类的接口转换成客户希望的另外一个接口。使得原本由于接口不兼容而不能一起工作的那些类可以一起工作
* * * 桥接模式：将抽象部分与实际部分分离，使他们都可以独立的变化
* * * 组合模式：将对象组合成树形结构以表示部分--整体的层次结构，使得用户对单个对象和组合对象的使用具有一致性
* * * 装饰模式：动态的给一个对象添加一些额外的职责，就增加功能来说，此模式比生成子类更为灵活
* * * 外观模式：为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用
* * * 享元模式：以共享的方式高效的支持大量细粒度的对象
* * * 代理模式：为其他对象提供一种代理以控制对这个对象的访问
* * 行为型模式
* * * 职责链模式：对象对其下家的引用穿成一条链，请求在链上传递，直到链上有对象处理此请求，使得系统可以在不影响客户端的情况下动态地重新组织链和分配责任
* * * 命令模式：将一个请求封装为一个对象，从而使你可用不同的请求对客户端进行参数化，对请求排队或记录或记录请求日志，以及支持可撤销的操作
* * * 解释器模式：如何为简单的语言定义一个语法，如何在该语言中表示一个句子，以及如何解释这些句子
* * * 迭代器模式：提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示
* * * 中介者模式：定义一个中介对象来封装系列对象之间的交互。中介者使对象不需要显示地相互调用，从而使得其耦合性松散，而且可以独立的改变他们之间的交互
* * * 备忘录模式：在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存
* * * 观察者模式：定义对象间的一种一对多的依赖关系，当一个对象的状态改变的时候，所有依赖于它的对象都得到通知并被自动更新
* * * 状态模式：对象的行为，依赖于它所处的状态
* * * 策略模式：准备一组算法，并将每一个算法封装起来，使得他们可以互换
* * * 模板方法模式：子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤
* * * 访问者模式：一个作用于某对象结构中各元素的操作，可以在不改变各元素的类的前提下定义作用于这些元素的新操作

### C++
* 智能指针是什么，为什么要智能指针
* shared_ptr, weak_ptr，unique_ptr
* 虚函数的实现方式，虚函数表
* 面向对象的三大特性
* 构造函数和析构函数可以是虚函数吗？为什么？
* C++11的新特性：移动语义，Lambda表达式
* const define static的区别，加在不同位置的作用（比如说成员函数上，可以改变成员属性吗）
* 类模板
* C++类访问权限修饰符以及公有继承保护继承私有继承的区别。
* STL：vector、list、map、set
* vector扩容
* hashmap，unordered_map
* sort底层
* 什么情况下回出现栈、堆内存溢出
* malloc最多能申请多少内存
* 手写memcpy

### 项目
* 6.824 mapreduce是怎么实现节点同步的
* * Ping，超时检测，重新分配
* Apache POI内存溢出的解决方法
* 内存溢出的解决方法
* 多个用户向服务器发送多个请求，如何知道他们是哪个用户发送的
* 需要不同版本的第三方包如何处理
* 想要保护数据隐私，在出现异常或者错误时，服务端如何避免将数据隐私泄露给用户
* 大量服务向redis拿缓存的解决办法
* redis加锁如果业务操作过长怎么办
* 低代码工具
* 一个tomcat启动，从操作系统的角度分析，它干了什么
* 字符流和字节流的区别，哪些文件适合字符流，哪些适合字节流，字节流可以读取文本文件么，那为什么要用字符流
* * 字符流解码没问题，字节流要解码
* 秒杀系统设计
* * 原则：四要一不要
* * * 数据要尽量少
* * * 请求数要尽量少，合并css和Javascript
* * * 路径要尽量短，减少中间的代理服务器数量
* * * 依赖要尽量少，强依赖不能去，比如商品信息，用户信息，但是弱依赖可以去掉，比如说优惠券、成交列表等，可以对系统进行分级，
* * * 不要有单点
* * 要求高性能、一致性、高可用
* * * 高性能：主要是解决并发读和并发写问题，数据动静分离，热点发现与隔离，请求削峰与分层过滤，服务器极致优化
* * * 一致性：库存减扣
* * * 高可用：plan B
* * 1W QPS，直接数据库
* * 10W QPS，独立集群抵挡流量洪峰，库存数据放入缓存，增加秒杀答题，防止有秒杀器抢单
* * 100W QPS，页面动静分离，减少动态请求，服务端缓存秒杀商品，不依赖后台服务获取数据，增加系统限流保护，通过策略的方式减少压力
* * 针对性处理热点数据：缓存（优化）、限制（放在一个哈希桶里，防止其他请求不能能用了）、隔离（业务隔离，系统隔离，数据隔离）
* * 流量削峰：无损：排队、答题（防止刷量作弊）、分层过滤（减少无用请求）；有损：限流，机器负载保护
* * 库存减扣：下单就减（恶意刷单）、付款才减（下单超了）、预扣超时恢复（恶意刷单）
* * 对于恶意刷单的打标记，设置最大购买数量
* * 秒杀的时候用下单减库存更合适，保证不是负的
* * 数据降级，返回数据减少，服务降级，限流
* 限流算法：令牌桶（token bucket）
* * 系统以恒定速率放令牌，请求需要处理需要先拿一个令牌
* * 桶里没有令牌的时候就拒绝服务
* * 桶最多放b个令牌，多了就丢掉，n个字节的请求到达，拿n个令牌，不足n个就等着或者删掉
* * 单速率双桶和双速率双桶，色盲模式、色敏模式，就是是否提前给了优先级
* * * 单速率双桶：色盲模式，小于小桶绿色，小桶大桶之间黄色，大于大桶红色，色敏模式，绿绿为绿，绿黄为黄，黄黄为黄，黄红为红，红红为红
* * * 双速率双桶：色盲模式，小于小桶绿色，小桶大桶之间黄色，大于大桶红色，色敏模式，绿红为红，绿黄为黄，绿绿为绿，黄色只比较大桶，黄红为红，黄黄为黄，红色直接扔

### 其他
* 设计模式
* git常用命令
* docker的理解，docker和虚拟机的区别
* docker底层资源隔离
* 大文件，求数字（单词）交集（是否排序）
* 大文件，求出现最多的单词（数字）
* 大文件，求最大的1000个数
* nacos服务发现原理（服务注册+内置dns解析）
* 微服务健康监测怎么实现
* 排序算法：哪些是稳定的

### Kafka
* 什么是消息队列，为什么要使用消息队列
* * 消息队列是应用间通信的方式，使得生产者生产的消息放入队列即可返回，消费者消费只管从MQ中取消息即可
* * 使用消息队列的原因：解耦、异步、削峰
* * * 解耦：生产者和消费者不需要互相调用接口，而是直接依赖于消息队列，比如订阅者发布者模式
* * * 异步：不需要调用都返回才继续操作，只要放入消息队列就可以了，消息队列保障可靠传递
* * * 削峰：可以把高峰期的请求保存在消息队列里，过了之后再解决
* * 缺点：系统可用性降低，如果消息队列崩了就都崩了，系统复杂性增加，一致性问题，前面的系统以为搞定了，但是后面崩了，不一致了
* 怎么保障消息不丢失
* * 生产阶段：生产者接收到消息队列的ACK才认为已经发送成功了消息
* * 消息队列：保障高可用，建立副本；持久化保存消息，保存到磁盘才给生产者回复ACK；
* * 消费阶段：消费者回复ACK才认为已经消费消息，消费者要执行完本地逻辑之后才回复ACK，要保证幂等
* 怎么保证消息顺序
* * Kafka只保证单一partition内有序
* * * 全局消费顺序：都发到一个partition里，并发没有了
* * * 局部消费顺序：各自发到partition里
* * * 做N个内存Queue，具有相同key的数据都到同一个内存queue，对于N个线程，每个线程分别消费一个内存queue即可保证顺序性
* 怎么防止重复消费，幂等
* * 通常来说需要消费者自己保证，kafka的消息都有一个offset作为序号，consumer消费之后每隔一段时间就会把自己消费过的数据的offset ack一下
* * 就算重启，kafka也会让消费者从上次消费的offset开始消费，但是如果消费了，但是没来得及ack就挂了，就会收到重复数据
* * 业务解决方案：
* * 1. 内存维护一个set，获取消息先看是否在set里，表示已经消费过了，不在就放进去
* * 2. 如果要写数据库，可以用唯一键先去数据库查一下
* * 3. 如果写redis没问题，set是天然的幂等
* * 4. 让生产者发的时候加上全局唯一id，消费的时候把id保存到redis里去，消费的时候先看redis有没有
* * 5. 数据库操作可以设置唯一键、防止重复插入
* 什么是消费组
* * 消费组内只有一个消费者可以消费消息
* Kafka、ActiveMQ、RocketMQ、RabbitMQ对比
* * Kafka功能简单，主要用于大数据日志采集等，是行业标准，吞吐量高
* * ActiveMQ最差，小规模可以
* * RabbitMQ是erlang开发，并发很好，效率极高，微妙级，并发没那么高
* * RocketMQ阿里Java
* * Kafka和RocketMQ理论不会丢消息，ActiveMQ和RabbitMQ丢的概率小
* * Kafka，是分布式的，每个broker是一个节点，创建一个topic可以划分为多个partition，partition可以放在不同的broker上，通过HA机制，备份，每个partition的多个备份选出一个leader，应用跟leader打交道，其他是follower就可以了
* * RabbitMQ，集群镜像模式基于主从架构实现高可用，
* AMQP协议、MQTT协议、STOMP协议、XMPP协议
* * 也有自己实现的协议，比如说Kafka，Redis
* 大量消息长期积压
* * 只能临时扩容了，修复consumer问题，保证恢复消费速度，然后停掉现有consumer
* * 新建一个topic，partition是原来的10倍，临时建立原来10倍的queue
* * 写一个临时分发数据的consumer程序，这个程序部署上去消费挤压的消息，消费之后不做耗时处理，直接均匀写入临时建立好的10个queue
* * 用临时的10倍机器来部署consumer，每一批consumer消费一个临时queue的数据，消费完之后再恢复
* MQ消息过期失效了怎么办
* * RabbitMQ可以设置过期时间，大量积压就会消息丢失
* * 可以用数据库保存这些消息，过了高峰期一点一点导出来，再消费
* 如何保证一致性，事务消息如何实现
* * 生产者发送消息，消息队列持久化，标记为待发送，先不发
* * 生产者处理本地逻辑，完事了再发一个事务执行结果，如果commit了，消息队列标记消息为可发送，否则删除，然后发给消费者
* * 如果长时间没看到消费者事务commit了，消息队列反问生产者，决定消息是发送还是删除