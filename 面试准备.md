## 面试准备
* MySQL
* Redis
* Linux
* 计网
* WebServer

### 数据结构
* 两个栈实现队列
* * 每次入队进一个栈
* * 每次出队看另一个栈是否为空，如果空把入栈的栈导到另一个空的，弹出栈底，把空栈设为入栈的栈；如果不为空，那么直接弹出栈顶
* * 并发情况？必须加锁
* 哈希表，哈希散列冲突，如何解决？
* * 开放寻址法（往后找个空的，好多方法找，主要是删的时候不能真正删，得打标记，下一个元素插入才能删）
* * 链
* * rehash
* * 公共溢出区
* 二叉搜索树、AVL、红黑树
* * 二叉搜索树退化成链表
* * AVL旋转太慢，记不住旋转，红黑树也记不住
* * 红黑树，保障最长路径不超过最短路径的两倍
* * 节点为红或者黑，根为黑，叶子结点（空的）为黑
* * 红节点的子节点为黑，红节点的父节点为黑，从根到叶子结点没有两个连续的红
* * 任意节点到叶节点的所有路径包括相同数目的黑
* * 红黑树和4阶B树有等价性，黑节点与红子节点融合为一个B树节点，
* B树、B+树
* R树、R+树
* 跳表skiplist，随机插入层数来维护
* 一致性散列
* 排序算法：冒泡、插入、快排、归并、桶排序等
* 小顶堆，小顶堆
* * 堆是完全二叉树，因此可以用数组表示
* * 大顶堆：每个节点都大于等于左右孩子，小顶堆，每个节点都小于等于左右孩子
* * 大顶堆：a[i] >= a[2i+1] && a[i] >= a[2i+2]
* * 小顶堆：a[i] <= a[2i+1] && a[i] <= a[2i+2]
* * 堆排序，构成一个大顶堆，然后最大值就是根节点，将其与末尾元素互换，此时末尾就是最大值，然后对n-1个元素重新构成一个堆，重复执行
* * 建堆的时候首先找到最后一个非叶节点，序号为length/2-1
* * 如果其左子结点大于它，那么就交换它和它的左子结点，然后查看它的左子树是否满足堆结构，如果不满足就要重新调整子树结构
* * 然后右子节点，右子树，然后找下一个非叶节点，也就是当前下标-1，重复过程直到建堆完成（一直减1）
* * 插入是放最后，然后调整；删除是删根，然后把最后一个放在根，然后调整
* 线段树（区间问题常用，最长上升自区间，），字典树（查找的，统计词频，内存展开了贼大， 前缀树过滤敏感词）
* 一个生产者，一个消费者，用循环队列做缓冲区，需要用锁实现同步吗？
* * 不需要直接用缓冲区读就行了
* 快速排序
* * 也是交换排序，但是每次选一个数，把大于它的和小于它的放在两边
```Golang
func quickSort(arr []int) []int {
    return _quickSort(arr, 0, len(arr)-1)
}

func _quickSort(arr []int, left, right int) []int {
    if left < right {
        partitionIndex := partition(arr, left, right)
        _quickSort(arr, left, partitionIndex-1)
        _quickSort(arr, partitionIndex+1, right)
    }
    return arr
}

func partition(arr []int, left, right int) int {
    pivot := left
    index := pivot + 1
	// 单指针定位
    for i := index; i <= right; i++ {
        if arr[i] < arr[pivot] {
        	// 以基准值作为交换参考，将所有小于基准值的数前移，
            swap(arr, i, index)
            // 索引
            index += 1
        }
    }
    // 将基准值调整到它最终要到的有序目标位置
    // 达到区间内基准值左侧比它小右边比它大,实现双指值双向移动的效果
    swap(arr, pivot, index-1)
    return index - 1
}

func swap(arr []int, i, j int) {
    arr[i], arr[j] = arr[j], arr[i]
}

```
* * 实现方法
* * * house：p从左、q从右，p碰到比选的数大就停下，q碰到比选的数小就停下，交换，直到pq相遇，和选择数交换
* * * 挖坑法：保存第一个数，从后找比第一个小的，放到第一个，从前找比第一个大的，放到最后一个，不断循环
* * * 快慢指针：快指针小于key，则交换快慢指针，并且让慢指针向前走
* * * 还可以实现栈的：把区间用两个数表示，入栈，每次出栈一个区间，化为左右区间入栈，直到不能
* * 快速排序的最好时间复杂度和最坏时间复杂度分别是多少
* * 最好O(nlogn)最坏O(n^2)，正序或倒序
* 归并排序
```Golang
package main

import (
	"fmt"
)
func mergeSort(nums []int) []int {
	if len(nums) < 2{
		// 分治，两两拆分，一直拆到基础元素才向上递归。
		return nums
	}
	i := len(nums) / 2
	left := mergeSort(nums[0:i])
	// 左侧数据递归拆分
	right := mergeSort(nums[i:])
	// 右侧数据递归拆分
	result := merge(left, right)
	// 排序 & 合并
	return result
}

func merge(left, right []int) []int {
	result := make([]int, 0)
	i, j := 0, 0
	l, r := len(left), len(right)
	for i<l && j<r{
		if left[i] > right[j]{
			result = append(result, right[j])
			j++
		}else {
			result = append(result, left[i])
			i++
		}
	}
	result = append(result, right[j:]...)
	result = append(result, left[i:]...)
	return result
}

func main() {
	arr := []int{8, 9, 5, 7, 1, 2, 5, 7, 6, 3, 5, 4, 8, 1, 8, 5, 3, 5, 8, 4}
	result := mergeSortgiao(arr)
	fmt.Println(result)
}

```
### 操作系统
* 进程和线程区别，协程
* 一个进程最多能创建多少个线程？
* 进程间通信方式
* 线程通信方式
* 线程安全，多线程并发控制
* linux常用命令：df，du，top，grep，telnet，curl，wget，netstat，sar，ls，cat，tail，
* linux文件权限
* SSH修改默认端口号
* 查看文件最后100行的命令，tail -n 100 my.log
* 进程I/O控制方法：阻塞、非阻塞、同步、异步
* I/O多路复用：select，poll，epoll
* 线程池
* 共享内存的函数：shmget,shmat,shmdt,shmctl
* * ipcrm -m id可以删除
* 死锁产生的机制，如何在项目中排查死锁，如何解决死锁
* LRU算法：Hashmap+双向链表
* * 双向链表建立起来以后保存在hashmap里，这样查询就是O(1)
* * 删除和插入的时候，删除可以通过hashmap找到双向链表的节点，然后根据前后指针就能删掉了，插入就放最后
* * 更新的时候和也是，插入和删除记得更新hashmap
* Buff都有过期时间，设计一个高效的管理器（Linux系统的timer）
* * 暂时不会
* 乐观锁和悲观锁
* * CAS是乐观锁，自旋锁是CAS实现的
* 内存页面置换
* * 
* 软件中断和硬件中断的处理流程
* * 
* lazy alloc
* * 缺页中断
* 内核有哪几个子系统
* * 虚拟内存（内存管理），进程管理，进程通信，文件系统，网络系统
* 内存页为什么要设置成4kb
* * 磁盘扇区读取，太大了每次换入换出太大了，太小了数据结构太大了

### 计算机网络
* TCP三次握手：两次行吗？四次行吗？历史连接，资源
* TCP四次挥手：为什么要有time wait？保障对方服务器正常关闭，避免历史连接
* TCP具体字段
* * 端口，长度，序列号，确认序列号，标志位，校验和，紧急指针URG，PSH是紧急推送，不等缓存满了
* 从输入url到页面显示的过程
* * DHCP，ARP，DNS，HTTP，TCP，IP，Ethernet，换MAC头，（OSPF，BGP）拆开，i/o多路复用，Nginx，Redis，后端数据库，浏览器加载
* 在网络层或者在应用层实现可靠数据传输
* * 对头阻塞，换网络，快速建立连接，QUIC
* RPC和HTTP的优劣
* * RPC二进制，比HTTP小
* * RPC头少，HTTP通用
* * gRPC基于HTTP2
* * RPC自带负载均衡，HTTP需要Nginx HAProxy
* 常用的RPC框架，thrift，gRPC
* 负载均衡（不同层级，DNS，反向代理，IP，MAC地址，软件硬件）
* ngnix，ngnix为什么要有分发，跨域是谁控制的
* http和https的区别，https为什么安全
* TLS四次握手，内涵与算法
* 对称加密和非对称加密
* * 先用非对称，后用对称，非对称慢，要大数乘法
* 对于一个银行取钱的业务，如何在传输层保障数据安全？请你设计流程？
* 对于传输层你设计的这个流程，是否需要设计应用层的安全保障机制？
* 假设当前我使用一个app看视频，使用了那些协议？
* 假如我要设计一个手机黑名单，我要用那种数据结构？
* 什么是tcp粘包，为什么会粘包？
* 在进行压测的时候用的是长连接还是短连接？HTTP长连接和短连接的应用场景？
* HTTP状态码，20，30，40，50
* session和cookie的关系和区别
* WebSocket和HTTP的关系
* HTTP Get一定没有Body吗？Post一定有Body吗？
* HTTP2.0和1.0的区别
* RequestBody和RequestParam区别
* DNS查询，递归查询和迭代查询

### 数据库
* 库存扣减
* InnoDB的锁问题，索引结构
* 聚簇索引
* InnoDB事务隔离级别
* 幻读、脏读，不可重复读
* SQL：limit后面加两个数字的含义，从某一个开始查多少个
* 视图
* 索引是不是越多越好
* SQL语句执行顺序，解释器、预处理器、优化器、执行器，InnoDB
* SQL语句优化
* mysql执行计划，慢查询日志：记录查询时间超过多久的SQL，explain
* MySQL给一些离散度较低的字段建立索引会出现什么问题？
* redo log undo log区别
* MySQL联合索引失效的场景
* MySQL的索引数据结构介绍，B+树
* GUID和UUID作为关键的索引会出现什么现象？
* * 合并的时候好，性能也好，比自增主键更不容易透露信息
* * 空间大可别搞成字符串了，具有随机性没有排序
* 场景题：如何建表，建表需要考虑哪些问题
* MySQL为什么是B+树
* 什么是最左匹配原则，距离说明是否用到了联合索引
* 如何检查慢查询并优化，慢查询日志，explain，索引
* 数据库多条件查询
* MySQL左查询和右查询的区别
* MySQL的分页
* 联合索引如果查询第一列中的"%a"可以吗
* 数据库的持久性如何实现，redolog
* SQL 选出每个用户的最近访问时间
* mysql乐观锁和悲观锁
* 左连接、右连接、全连接那个快，什么场景用，左大于内，大于全

### 分布式系统
* 分布式锁：zookeeper，Redis
* 分布式事务：2PC，Seeta，3PC，TCC
* 分布式事务的使用场景和实现方式
* 分布式事务如何通过消息队列来实现不同节点之间的事务协调和数据交互
* 脑裂
* 缓存一致性
* redis缓存雪崩，缓存击穿，缓存穿透，解决办法？
* redis主从复制
* redis数据结构
* redis+lua库存扣减
* redis+lua的原子性
* redis set指令
* redis rehash
* redis 延时队列
* redis 集群模式
* redis key过期策略
* redis 缓存删除策略
* redis 内存淘汰机制
* redis 的持久化机制 数据类型
* Redis 持久性，RDB方式为什么fork一个子进程就不阻塞主进程了？（COW）
* Redis AOF缓存区 刷盘时机？如果交给操作系统，操作系统如何决定什么时候刷盘？
* Redis 压缩列表缺点？ 为了能够倒序遍历，entry里的长度记录的是前一个entry的长度。
* Redis 字符串怎么扩容的？
* Redis IO多路复用机制了解吗？
* redis 一致性哈希如何用？怎么判断slot属于哪一个节点，初始化怎么分配slot？
* redis 日志框架 日志级别
* redis 哨兵
* MySQL的缓存和redis的缓存有什么区别
* 分布式分库分表
* 如何保证缓存和数据库数据的一致性？
* MQ如何保障消息不丢失？如何保证消息的顺序性？
* MQ怎么确定生产者确实发布了消息，消费者确实收到了消息
* rocketmq的特性，怎么支持重试，生产者消费者模式
* rabbitmq消息堆积，高并发？
* Kafka怎么保证消息不丢失
* Kafka消息消费幂等性
* 集群环境怎么更新本地缓存？
* 什么时候用到缓存，Redis和Memcache的区别，各自使用的场景
* 微服务用过哪些？
* es怎么用的

### C++
* 智能指针是什么，为什么要智能指针
* shared_ptr, weak_ptr，unique_ptr
* 虚函数的实现方式，虚函数表
* 面向对象的三大特性
* 构造函数和析构函数可以是虚函数吗？为什么？
* C++11的新特性：移动语义，Lambda表达式
* const define static的区别，加在不同位置的作用（比如说成员函数上，可以改变成员属性吗）
* 类模板
* C++类访问权限修饰符以及公有继承保护继承私有继承的区别。
* STL：vector、list、map、set
* vector扩容
* hashmap，unordered_map
* sort底层
* 什么情况下回出现栈、堆内存溢出
* malloc最多能申请多少内存
* 手写memcpy

### 项目
* 6.824 mapreduce是怎么实现节点同步的
* * 在每个阶段设置一个chan，worker从coordinator那里间歇性请求任务
* * coordinator看阶段，然后看chan有没有数据了，有就分发，否则等待
* * coordinator设置一个检查是否超时的goroutine，超时就把任务重新放回对应的chan
* Raft选主过程
* * 触发：心跳检测超时
* * 遍历peer，发送request
* * 如果Term小，则不同意，如果Term大则更新，如果一样，则看当前是否已经投票了，
* * 如果投了，就不再投了，否则认可
* * 收到半数就成为leader，发送一个空的日志，用来提交没有还提交的log，以及删除不能再提交的log
* * 这样leader就拿到了所有的最新的log
* Raft preVote
* * 就是说在Vote之前先preVote一次，条件都是一样的，就是看是否能成功
* * 如果能成功才Vote，这样防止分区的Raft节点Term贼高，回来打断正常运行
* * 并且只有能成功的才Vote，防止资源浪费
* Raft快速log复制
* * 如果当前节点log比发过来的短，就告诉现在我有多长
* * 如果一样长但是Term不对，就告诉我上一个Term最后的index是多少
* * leader保存nextIndex数组，在减的时候直接减一个长度，把后面的log都发过去
* * 如果都到了snapshot之前了，就发snapshot和所有log
* Apache POI内存溢出的解决方法
* 内存溢出的解决方法
* 多个用户向服务器发送多个请求，如何知道他们是哪个用户发送的
* 需要不同版本的第三方包如何处理
* 想要保护数据隐私，在出现异常或者错误时，服务端如何避免将数据隐私泄露给用户
* 大量服务向redis拿缓存的解决办法
* redis加锁如果业务操作过长怎么办，超时机制，客户端来续约
* 低代码工具
* 一个tomcat启动，从操作系统的角度分析，它干了什么
* 字符流和字节流的区别，哪些文件适合字符流，哪些适合字节流，字节流可以读取文本文件么，那为什么要用字符流
* * 字符流解码没问题，字节流要解码
* 秒杀系统设计
* * 原则：四要一不要
* * * 数据要尽量少
* * * 请求数要尽量少，合并css和Javascript
* * * 路径要尽量短，减少中间的代理服务器数量
* * * 依赖要尽量少，强依赖不能去，比如商品信息，用户信息，但是弱依赖可以去掉，比如说优惠券、成交列表等，可以对系统进行分级，
* * * 不要有单点
* * 要求高性能、一致性、高可用
* * * 高性能：主要是解决并发读和并发写问题，数据动静分离，热点发现与隔离，请求削峰与分层过滤，服务器极致优化
* * * 一致性：库存减扣
* * * 高可用：plan B
* * 1W QPS，直接数据库
* * 10W QPS，独立集群抵挡流量洪峰，库存数据放入缓存，增加秒杀答题，防止有秒杀器抢单
* * 100W QPS，页面动静分离，减少动态请求，服务端缓存秒杀商品，不依赖后台服务获取数据，增加系统限流保护，通过策略的方式减少压力
* * 针对性处理热点数据：缓存（优化）、限制（放在一个哈希桶里，防止其他请求不能能用了）、隔离（业务隔离，系统隔离，数据隔离）
* * 流量削峰：无损：排队、答题（防止刷量作弊）、分层过滤（减少无用请求）；有损：限流，机器负载保护
* * 库存减扣：下单就减（恶意刷单）、付款才减（下单超了）、预扣超时恢复（恶意刷单）
* * 对于恶意刷单的打标记，设置最大购买数量
* * 秒杀的时候用下单减库存更合适，保证不是负的
* * 数据降级，返回数据减少，服务降级，限流
* 限流算法：令牌桶（token bucket）
* * 系统以恒定速率放令牌，请求需要处理需要先拿一个令牌
* * 桶里没有令牌的时候就拒绝服务
* * 桶最多放b个令牌，多了就丢掉，n个字节的请求到达，拿n个令牌，不足n个就等着或者删掉
* * 单速率双桶和双速率双桶，色盲模式、色敏模式，就是是否提前给了优先级
* * * 单速率双桶：色盲模式，小于小桶绿色，小桶大桶之间黄色，大于大桶红色，色敏模式，绿绿为绿，绿黄为黄，黄黄为黄，黄红为红，红红为红
* * * 双速率双桶：色盲模式，小于小桶绿色，小桶大桶之间黄色，大于大桶红色，色敏模式，绿红为红，绿黄为黄，绿绿为绿，黄色只比较大桶，黄红为红，黄黄为黄，红色直接扔

### 其他
* 设计模式
* git常用命令
* docker的理解，docker和虚拟机的区别
* docker底层资源隔离
* 大文件，求数字（单词）交集（是否排序）
* 大文件，求出现最多的单词（数字）
* 大文件，求最大的1000个数
* nacos服务发现原理（服务注册+内置dns解析）
* 微服务健康监测怎么实现
* 排序算法：哪些是稳定的

### Kafka
* 什么是消息队列，为什么要使用消息队列
* * 消息队列是应用间通信的方式，使得生产者生产的消息放入队列即可返回，消费者消费只管从MQ中取消息即可
* * 使用消息队列的原因：解耦、异步、削峰
* * * 解耦：生产者和消费者不需要互相调用接口，而是直接依赖于消息队列，比如订阅者发布者模式
* * * 异步：不需要调用都返回才继续操作，只要放入消息队列就可以了，消息队列保障可靠传递
* * * 削峰：可以把高峰期的请求保存在消息队列里，过了之后再解决
* * 缺点：系统可用性降低，如果消息队列崩了就都崩了，系统复杂性增加，一致性问题，前面的系统以为搞定了，但是后面崩了，不一致了
* 怎么保障消息不丢失
* * 生产阶段：生产者接收到消息队列的ACK才认为已经发送成功了消息
* * 消息队列：保障高可用，建立副本；持久化保存消息，保存到磁盘才给生产者回复ACK；
* * 消费阶段：消费者回复ACK才认为已经消费消息，消费者要执行完本地逻辑之后才回复ACK，要保证幂等
* 怎么保证消息顺序
* * Kafka只保证单一partition内有序
* * * 全局消费顺序：都发到一个partition里，并发没有了
* * * 局部消费顺序：各自发到partition里
* * * 做N个内存Queue，具有相同key的数据都到同一个内存queue，对于N个线程，每个线程分别消费一个内存queue即可保证顺序性
* 怎么防止重复消费，幂等
* * 通常来说需要消费者自己保证，kafka的消息都有一个offset作为序号，consumer消费之后每隔一段时间就会把自己消费过的数据的offset ack一下
* * 就算重启，kafka也会让消费者从上次消费的offset开始消费，但是如果消费了，但是没来得及ack就挂了，就会收到重复数据
* * rabbitmq就需要业务解决方案保证幂等，开启confirm或transaction可以确保不丢失数据，但是幂等需要处理
* * 业务解决方案：
* * 1. 内存维护一个set，获取消息先看是否在set里，表示已经消费过了，不在就放进去
* * 2. 如果要写数据库，可以用唯一键先去数据库查一下
* * 3. 如果写redis没问题，set是天然的幂等
* * 4. 让生产者发的时候加上全局唯一id，消费的时候把id保存到redis里去，消费的时候先看redis有没有
* * 5. 数据库操作可以设置唯一键、防止重复插入
* 什么是消费组
* * 消费组内只有一个消费者可以消费消息
* Kafka、ActiveMQ、RocketMQ、RabbitMQ对比
* * Kafka功能简单，主要用于大数据日志采集等，是行业标准，吞吐量高
* * ActiveMQ最差，小规模可以
* * RabbitMQ是erlang开发，并发很好，效率极高，微妙级，并发没那么高
* * RocketMQ阿里Java
* * Kafka和RocketMQ理论不会丢消息，ActiveMQ和RabbitMQ丢的概率小
* * Kafka，是分布式的，每个broker是一个节点，创建一个topic可以划分为多个partition，partition可以放在不同的broker上，通过HA机制，备份，每个partition的多个备份选出一个leader，应用跟leader打交道，其他是follower就可以了
* * RabbitMQ，集群镜像模式基于主从架构实现高可用，
* AMQP协议、MQTT协议、STOMP协议、XMPP协议
* * 也有自己实现的协议，比如说Kafka，Redis
* 大量消息长期积压
* * 只能临时扩容了，修复consumer问题，保证恢复消费速度，然后停掉现有consumer
* * 新建一个topic，partition是原来的10倍，临时建立原来10倍的queue
* * 写一个临时分发数据的consumer程序，这个程序部署上去消费挤压的消息，消费之后不做耗时处理，直接均匀写入临时建立好的10个queue
* * 用临时的10倍机器来部署consumer，每一批consumer消费一个临时queue的数据，消费完之后再恢复
* MQ消息过期失效了怎么办
* * RabbitMQ可以设置过期时间，大量积压就会消息丢失
* * 可以用数据库保存这些消息，过了高峰期一点一点导出来，再消费
* 如何保证一致性，事务消息如何实现
* * 生产者发送消息，消息队列持久化，标记为待发送，先不发
* * 生产者处理本地逻辑，完事了再发一个事务执行结果，如果commit了，消息队列标记消息为可发送，否则删除，然后发给消费者
* * 如果长时间没看到消费者事务commit了，消息队列反问生产者，决定消息是发送还是删除
* * kafka的事务是有一个事务协调中心，给事务分配transactionid，本来幂等只能支持同一个分区消息不重复，但是事务把pid和transactionid一一对应，就算换了，也会立刻把前一个pid停用，多分区写入也是原子的
* * kafka幂等就是把pid和分区绑定，这样单分区就一定是不重复，和at least once搭配就达到了exactly once的效果
* 雪花算法
* * 分布式生成唯一id，一秒百万级，可扩展
* * 41位时间戳，5位机器id，5位服务id，12位序号
* * 主要是递增的，这样mysql主键id，就不会插入，导致节点分裂等
* * 缺点就是机器时钟回拨会重复id