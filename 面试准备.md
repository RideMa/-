## 面试准备
* MySQL
* Redis
* Linux
* 计网
* WebServer

### 数据结构
* 两个栈实现队列
* 两个栈实现并发队列
* 哈希表，哈希散列冲突，如何解决？
* 二叉搜索树、AVL、红黑树
* B树、B+树
* R树、R+树
* 跳表skiplist
* 一致性散列
* 排序算法：冒泡、插入、快排、归并、桶排序等
* 小根堆，小顶堆
* 线段树，字典树
* 前缀树过滤敏感词
* 一个生产者，一个消费者，用循环队列做缓冲区，需要用锁实现同步吗？
* MongoDB做什么的
* 快速排序的最好时间复杂度和最坏时间复杂度分别是多少

### 操作系统
* 进程和线程区别，协程
* 一个进程最多能创建多少个线程？
* 进程间通信方式
* 线程通信方式
* 线程安全，多线程并发控制
* linux常用命令：df，du，top，grep，telnet，curl，wget，netstat，sar，ls，cat
* linux文件权限
* SSH修改默认端口号
* 查看文件最后100行的命令
* 进程I/O控制方法
* I/O多路复用：select，poll，epoll
* 线程池
* 共享内存的函数
* 死锁产生的机制，如何在项目中排查死锁，如何解决死锁
* LRU算法：Hashmap+链表
* Buff都有过期时间，设计一个高效的管理器（Linux系统的timer）
* 乐观锁和悲观锁
* 内存页面置换
* 软件中断和硬件中断的处理流程
* lazy alloc
* 内核有哪几个子系统
* 内存页为什么要设置成4kb

### 计算机网络
* TCP三次握手：两次行吗？四次行吗？
* TCP四次挥手：为什么要有time wait？
* TCP具体字段
* 从输入url到页面显示的过程
* 在网络层或者在应用层实现可靠数据传输
* RPC和HTTP的优劣
* 常用的RPC框架，thrift，gRPC
* 负载均衡（不同层级，DNS，反向代理，IP，MAC地址，软件硬件）
* ngnix，ngnix为什么要有分发，跨域是谁控制的
* http和https的区别，https为什么安全
* TLS四次握手，内涵与算法
* 对称加密和非对称加密
* 对于一个银行取钱的业务，如何在传输层保障数据安全？请你设计流程？
* 对于传输层你设计的这个流程，是否需要设计应用层的安全保障机制？
* 假设当前我使用一个app看视频，使用了那些协议？
* 假如我要设计一个手机黑名单，我要用那种数据结构？
* 什么是tcp粘包，为什么会粘包？
* 在进行压测的时候用的是长连接还是短连接？HTTP长连接和短连接的应用场景？
* HTTP状态码
* session和cookie的关系和区别
* WebSocket和HTTP的关系
* HTTP Get一定没有Body吗？Post一定有Body吗？
* HTTP2.0和1.0的区别
* RequestBody和RequestParam区别
* DNS查询，递归查询和迭代查询
### 数据库
* 库存扣减
* InnoDB的锁问题，索引结构
* 聚簇索引
* InnoDB事务隔离级别
* 幻读、脏读，不可重复读
* SQL：limit后面加两个数字的含义
* 视图
* 索引是不是越多越好
* SQL语句执行顺序
* SQL语句优化
* mysql执行计划，慢查询日志
* MySQL给一些离散度较低的字段建立索引会出现什么问题？
* Mybatis Plus的执行顺序。
* redo log undo log区别
* MySQL联合索引失效的场景
* MySQL的索引数据结构介绍
* GUID和UUID作为关键的索引会出现什么现象？
* 场景题：如何建表，建表需要考虑哪些问题
* MySQL为什么是B+树
* 什么是最左匹配原则，距离说明是否用到了联合索引
* 如何检查慢查询并优化
* 数据库多条件查询
* MySQL左查询和右查询的区别
* MySQL的分页
* 联合索引如果查询第一列中的"%a"可以吗
* 数据库的持久性如何实现
* SQL 选出每个用户的最近访问时间
* mysql乐观锁和悲观锁
* 左连接、右连接、全连接那个快，什么场景用

### 分布式系统
* 分布式锁：zookeeper，Redis
* 分布式事务：2PC，Seeta，3PC，TCC
* 分布式事务的使用场景和实现方式
* 分布式事务如何通过消息队列来实现不同节点之间的事务协调和数据交互
* 脑裂
* 缓存一致性
* redis缓存雪崩，缓存击穿，缓存穿透，解决办法？
* redis主从复制
* redis数据结构
* redis+lua库存扣减
* redis+lua的原子性
* redis set指令
* redis rehash
* redis 延时队列
* redis 集群模式
* redis key过期策略
* redis 缓存删除策略
* redis 内存淘汰机制
* redis 的持久化机制 数据类型
* Redis 持久性，RDB方式为什么fork一个子进程就不阻塞主进程了？（COW）
* Redis AOF缓存区 刷盘时机？如果交给操作系统，操作系统如何决定什么时候刷盘？
* Redis 压缩列表缺点？ 为了能够倒序遍历，entry里的长度记录的是前一个entry的长度。
* Redis 字符串怎么扩容的？
* Redis IO多路复用机制了解吗？
* redis 一致性哈希如何用？怎么判断slot属于哪一个节点，初始化怎么分配slot？
* redis 日志框架 日志级别
* redis 哨兵
* MySQL的缓存和redis的缓存有什么区别
* 分布式分库分表
* 如何保证缓存和数据库数据的一致性？
* MQ如何保障消息不丢失？如何保证消息的顺序性？
* MQ怎么确定生产者确实发布了消息，消费者确实收到了消息
* rocketmq的特性，怎么支持重试，生产者消费者模式
* rabbitmq消息堆积，高并发？
* Kafka怎么保证消息不丢失
* Kafka消息消费幂等性
* 集群环境怎么更新本地缓存？
* 什么时候用到缓存，Redis和Memcache的区别，各自使用的场景
* 微服务用过哪些？
* es怎么用的


### Golang
* go语言协程的实现机制，为什么要用协程，什么是GMP模型
* * go关键字会产生一个Goroutine，其实是一个用户态线程，用户态线程没有时钟中断，就不会强制退出，因此看起来是在协作，也就是协程
* * 用户态线程保存栈和寄存器，使用ucontext来实现的协程，协程创建默认2KB
* * Golang在运行的时候有一个调度器，用GMP模型调度所有的Goroutine，其非Goroutine分配时间，将操作系统线程和逻辑处理器绑定，在逻辑处理器上运行Goroutine，调度器在任何给定时间都会全面控制goroutine要在哪个逻辑处理器上运行
* * G：goroutine，M：内核态线程，P：逻辑处理器
* * P最多GOMAXPROCS个，初始化保存在一个数组里，默认是CPU数；这也意味着同一时刻最多GOMACPROCS个G在运行
* * M最大默认是10000个，一个M阻塞了会创建新的M
* * 基本运行方式是，M获取一个P，然后从P的本地队列里拿G运行，运行一会以后把G放到P的末尾，然后再从P里拿一个，如果没有了就从Global里拿，如果没有就从别的P那里拿一半过来，如果还没有就进入线程池休眠
* * P会周期性查看Global里是否有G等待调度到M里
* * 当G阻塞系统调用的时候，M将会释放P，进而某个空闲的M1会获得P，继续执行P队列剩下的G
* * M带着G系统调用完了，如果有空闲的P，就进队，继续执行，没有就进Global，M进线程池睡眠
* * 当G执行channel读写、网络poll、定时器等操作的时候，会把G设置为WAITING状态，不再运行，当有结果了以后，对应的G放在全局队列里
* * Golang提供的网络接口是阻塞调用，但是底层是epoll的非阻塞I/O，会放到wait里去，epoll有结果了在唤醒，放global里
* * 一个G运行了很久，会被打标记，执行函数调用的时候会被抢掉（最多10ms）
* * 线程复用：work steal 没活干了不是销毁，而是别的地方找任务；hand out 当绑定的线程因为系统调用阻塞了，就释放，把P给别的空闲的M执行
* * 由于局部性原理，G1创建的G2会放在同一个P里，调度的时候，G1先让出P，然后G0（schedule）到P里做调度，让G2接着被M带着运行
* go管道底层是怎么实现的，有缓冲管道和无缓冲管道
* * Go有经常被使用的设计模式是不要通过共享内存的方式通信，CSP模型
* * channel是一个管道型的解决方案，但是其实也是基于内存的通信，不过不需要像管道那样进入内核态，只要在用户态就可以完成
* * 
* * channel底层是一个环形队列，结构体
```go
type hchan struct {
    qcount uint // 队列中的总元素个数
    dataqsiz uint // 环形队列大小，即可存放元素的个数
    buf unsafe.Pointer // 环形队列指针
    elemsize uint16 //每个元素的大小
    closed uint32 //标识关闭状态
    elemtype *_type // 元素类型
    sendx uint // 发送索引，元素写入时存放到队列中的位置

    recvx uint // 接收索引，元素从队列的该位置读出
    recvq waitq // 等待读消息的goroutine队列
    sendq waitq // 等待写消息的goroutine队列
    lock mutex //互斥锁，chan不允许并发读写
}
```
* * channel中读数据
* * 1. 如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒
* * 2. 如果等待发送队列不为空，则缓冲区已满，从缓冲区首部读出数据，把G中数据写入缓冲区尾部，把G唤醒
* * 3. 如果缓冲区有数据，则从缓冲区取出数据，结束读取。将当前goroutine放入recvq，进入睡眠，等待被写goroutine唤醒
* * channel中写数据
* * 1. 如果等待接收队列recvq不为空，则缓冲区为空或者没有缓冲区，直接从recvq中取出G，把数据写入，唤醒G
* * 2. 缓冲区有空余位置，写入缓冲区
* * 3. 缓冲区没有空余位置，则将发送数据写入G，将当前G加入sendq，进入睡眠，等待唤醒
* * 关闭channel
* * * 会将recvq中的所有G唤醒，本该写入G的数据位置为nil
* * * 将sendq中所有G唤醒，但是这些G会panic
* * nil的channel读写都会阻塞住，一般用在select里，就不会到达这个分支了
* 无缓冲的管道在没有接受者条件下能正常接受数据吗
* * 会阻塞，死锁
* 管道关闭了写数据会咋样
* * 我的经历是会报错，panic，程序退出
* * 读取的时候还可以读到，或者nil
* context的作用，结构的原理
* * 可以控制一组树状结构的Goroutine，每个goroutine有相同的上下文，是并发安全的，控制多个协程之间的协作、取消操作
```go
type Context interface {
    Deadline() (deadline time.Time, ok bool)
    Done() <-chan struct{}
    Err() error
    Value(key interface{}) interface{}
}
```
* * Deadline方法，可以获取截止时间，到了这个时间，context就会发起取消请求，返回值ok表示是否设置了截止时间
* * Done方法返回一个只读chan，如果可以读取，表示发出了取消信号，可以做清理操作，然后退出协程，释放资源
* * Err返回Context被取消的原因，Value方法获取Context上绑定的值，是一个键值对
* * background和TODO可以创建Context，前者一般是所有的父亲，后者是避免参数为nil
* * context可以派生context，然后以第一个参数的形式传递，从而可以在后续的goroutine里跟踪超时、跟踪数值
* * 当超时发生时，派生的所有context都会取消，或者取消调用后，也会取消所有子context，调用Done就发现能读到东西，就取消了
* * 控制超时可以节省资源，其实就是拥有同样上下文的一组Goroutine可以被同时取消掉
* * valueCTX没有子节点信息，只有一个父节点，可以网上找value
* * 上游可以取消下游任务，下游不会影响上游
* * 上游是通知下游可以取消了，下游可以自行决定是否取消
* waitgroup实现
* * 源码很简单
```go
type WaitGroup struct {
	noCopy noCopy
	state1 [3]uint32
}
```
* * noCopy表示不可复制，传递的时候只能传指针
* * state1包含counter总数、waiter等待数、sema信号量
* * add的时候给counter加1，done给counter减1，counter的时候唤醒waiter数量的goroutine
* * ADD的实现就是给counter加1，然后看是否counter是0，如果是，就唤醒wait，done就是ADD(-1)
* * wait的实现就是看counter是不是0，如果是就不用等了，否则给wait加1，阻塞等待唤醒
* select怎么用
```go
select {
	case <- chan1:
		// 如果 chan1 成功读到数据，则进行该 case 处理语句
	case chan2 <- 1:
		// 如果成功向 chan2 写入数据，则进行该 case 处理语句
	default:
		// 如果上面都没有成功，则进入default处理流程
}
```
* * 如果都没成功也没有default就阻塞
* * select可以控制超时（和<-context.Done()组合），或者到一定时间给某个chan写一个数，或者使用time.After(...)
* * 具体实现原理是每个case是一个结构体，保存在一个数组里，select执行一个函数，锁定所有channel，如果有ready的就执行
* * 如果都没ready也没default，就把当前协程放到所有channel的等待队列，唤醒后对应进行读写操作
* Gin
* * 是一个go的web框架，类似于flask，性能高效
* defer和return
* * return是两步，给返回值赋值、然后执行ret
* * defer在两者之间，
* * 两个defer会先执行后面的
* * 如果返回值是命名的，那么defer会改变那个返回值，也就会影响了
* * 即使panic，也会执行defer的东西，因此，如果在defer中执行recover捕获了异常，也就不会panic了
* slice和map底层实现
* * slice底层是一个指针，一个len和一个capcity，指针指向一个数组
* * map底层是两个buckets列表，每个列表元素是一个链表的头部，根据hash值来找slot，然后再放到链表里
* * slice扩容策略：
* * 1. 如果新的容量大于原来的两倍，那就是新的容量
* * 2. 如果旧的长度小于1024，那就翻倍
* * 3. 如果旧的长度大于等于1024那就是原来的1.25倍
* * 4. 如果计算出来的cap溢出了，那最终计算出来的cap就是新容量
* * 如果扩容到了原来的数组上，那就容易出bug
* * 如果没有超过cap，就不会重新分配内存
* * slice分配内存和垃圾回收是最大的挑战，拷贝内存问题不大，如果频繁修改用list会比较好，list是双向链表（我咋感觉不对）
* * map有两个buckets，发生扩容的时候记录扩容前的buckets数组指针
* * map是hmap，指向buckets，buckets是bmap，一个buckets里有若干个bmaps（2^B，取hash值的后B位作为桶的标识）
* * 一个bmap指向8个keyvalue对，如果超过了8个，就用overflow指向下一个bmap
* * bmap会维护一个tophash即高8位，意思是如果高8位都不满足，那肯定不满足
* * map扩容有两种，等量扩容和2倍扩容
* * 等量扩容就是由于删删改改，可能有空洞，不换桶，就把桶内的空洞补一补，也是要搬到新的里面去的！
* * 两倍扩容的时候可能会换桶，桶的数量变化，B+1.那么多取一位hash，如果是0就不变，如果是1，就放到新的桶里去
* * 扩容条件：装载因子=map中元素个数/当前的桶个数，即每个桶平均个数
* * 如果装载因子大于6.5就要扩容，或者B小于15，overflow的buckets数超过2^B，或者B>=15，overflow的bucket数大于2^15
* * 对于前一个条件，B+1也就是2倍扩容即可，对于后一个条件，等量扩容即可
* * 扩容的时候不是一下搬完，每次更新插入和删除都只移动两个Bucket
* * math.NaN()每次计算结果都不一样，按照tophash的最后一位判断在新的桶还是旧的桶
* slice和map是线程安全的吗
* * 都不是线程安全的
* * map并发写入的时候会直接panic，要写的时候需要加Mutex锁
* map的元素为什么不能取地址
* * 因为扩容之后位置可能就变了，通过unsafe得到的地址不能长期持有
* go语言什么数据类型可以比较
* * 浮点、字符串、布尔、复数、指针、chan（同一个make，或都nil）、数组
* * 结构体也可以比较，前提是字段都可以比较，并且类型、个数、顺序一致
* * 接口是靠结构体实现的，所以比较就是结构体比较
* * nil可能不相等，因为类型可能不一样
* * slice、map、function不可比较，但是可以和nil比较
* * nil的slice和空的slice不一样
* new和make的区别
* * new返回的是指针，make是值类型
* * make只能slice、chan、map
* * new会把分配的内存区域清零，make会初始化
* 垃圾回收原理
* * go自带垃圾回收，也就是清除不可达对象
* * v1.3之前是暂停业务逻辑，标记不可达、标记完了开始清除，然后再跑
* * 三色标记法
* * 新创建的对象默认是白色，每次GC回收的时候都会从根节点开始遍历对象，放入灰色集合，遍历灰色对象，把灰色对象引用的放入灰色，自己进入黑色，直到没有灰色，回收白色
* * 不采用STW保护，会出现白色对象被黑色对象引用，灰色对象与它之间的可达关系的白色对象遭到破坏
* * 强三色不等式：强制不允许黑色对象引用白色对象
* * 弱三色不等式：黑色对象可以引用白色，如果白色对象有其他链路被灰色对象引用
* * 插入屏障：A对象引用B对象的时候B对象变为灰色，只有堆上的对象需要屏障，栈上不触发，因为清除的时候要重新扫描一遍栈
* * 问题：最后还要STW扫描栈
* * 删除屏障：被删除的对象，如果自身位灰色或白色，则被标记为灰色
* * 问题：精度低，一个被删除的对象，指向它的指针下一轮才会被删除
* * Go V1.8之后是三色标记法+混合写屏障机制
* * 1. 开始把栈上对象全标记为黑色
* * 2. GC期间，在栈上新建的对象都是黑色
* * 3. 被删除和添加的对象标记为灰色
* * GO的GC为每个P都分配了gcMarker，有的P在回收，有的P在继续运行用户协程
* * 如果P没事干，也偷不到东西，就执行gcMarker
* * GC出发模式
* * 1. 辅助模式，堆内存到了上次GC的两倍，启动新一轮GC
* * 2. 调用runtime.GC阻塞启动一轮GC
* * 3. sysmon是运行时守护协程，超过runtime.forcegcperiod，默认2分钟没执行GC就来一轮
* * GOGC参数来调节，表示GC触发时占用内存的比例，0-100
* * Java是代际的，不同生命周期长度在不同的区域，不同区域不同算法
* Go语言有什么优势，为什么选择go，和Java，C++的区别
* * 
* Go为什么天然支持高并发
* * goroutine，GMP
* Go的继承和多态
* * 继承就是struct里有父类
```go
type Student struct {
    Name string     //姓名
    Age int         //年龄
    Score int   //成绩
}

type Pupil struct {
    Student
}

type Graduate struct {
    Student
}
```
* * 多态是interface实现的
* * 也就是说子类可以分别实现一个接口，然后调用的时候用接口的var来调用，就是不同的函数
* Go强类型、弱类型
* * 强类型，主要是强类型少隐式转换，弱类型会隐式转换
* Go内存管理模型
* * 采用Google的TCMalloc算法
* * 每个线程维护一个独立的内存池，内存分配的时候从内存池里分配，内存池不够了才加锁，向全局内存池申请，减少系统调用的损耗
* * 内存切的非常细，分为多级管理，降低锁的粒度
* * 回收对象不是释放内存，先放到大块内存里，空闲内存多了才释放
* * mspan是内存管理的基本单元，每个mspan管理一个8KB的页，Go有68种大小的spanClass，用于小对象的分配
* * 大于32K的对象会从堆里分配，一个特殊的span
* * mcache，每个P都有一个，mheap是唯一的，
* * Go的微对象、小对象、大对象
* * * 微对象小于16B，先线程缓存微分配器，然后线程缓存、中心缓存、堆
* * * 小对象16B到32k，先线程缓存，再中心缓存，再堆
* * * 大对象大于32K，直接堆
* * 内存碎片处理算法，为什么有stop the world，刚开始是全部STW，后来三色标记法是最后扫描栈和清理的时候STW，后面是只有打开写屏障的时候STW。主要是不STW的话，就会破坏强三色不等式
* Sync.map为什么线程安全
* * 性能比map加sync.Mutex好，比加读写锁也好得多
* * 里面有一个read_map和一个dirty_map
* * 读的时候从read_map里读，读到了就ok，没读到就要看dirty_map和read_map是否有差异，如果有就要锁住整个map，然后去读，发现read_map没读到，但是dirty_map读到了，就要记录一个miss
* * miss多了就把dirty_map升级成read_map
* * 更新操作
* * 1. 存储过程遵循互不影响的原则，如果在read map中读到，就只更新readmap，否则只更新dirtymap
* * 2. 优先从readmap读，更新失败才读dirtymap
* * 3. 存储新的值，如果readmap有，dirtymap没有，就要刷一遍dirtymap
* * 删除操作直接删除read_map的值
* * 无论存储还是读取，read map的值肯定能在dirtymap中找到
* * 当存储新值时，一定发生在dirty map中，当读取旧值时，如果read map读到就返回，否则加锁去dirty读，因此读多写少很合适
* Sync.Mutex实现原理
* * 主要是信号量PV操作，借助了atomic
* * 一个状态一个信号量用来唤醒goroutine
* * 状态分为四个部分，等待者数量，是否有唤醒的，饥饿模式、锁定否
* * 正常模式等待着FIFO，但是第一个被唤醒的可能争不过正在运行的
* * 饥饿模式直接递交给第一个等待的，新来的不会自旋，直接排在最后
* * 正常模式性能好，但是饥饿模式可以避免病态情况的尾部延迟
* * 加锁分为三种情况，无冲突，CAS加锁；有冲突，开始自旋，没成功就调用semrelease，进入等待状态
* unsafe是啥
* * 可以做指针类型转换，直接转不行的
* * 比如把slice底下的数组转成指针
* * unsafe的指针还能搞运算，转成uintptr，算完再转回来
* * sizeOf、Alignof、Offsetof用来获取大小、对齐、偏移
* * 本来指针不能运算，不能转换，不能比较，unsafe在源码里很多
* 原子操作，atomic
* * 依赖硬件指令，并且需要运行时调度器配合
* * 函数被编译器专门编译成使用CPU指令进行
* * 原子值修改的时候Goroutine不应该抢占，需要锁定MP的绑定关系
* Go内存逃逸，竞态
* * 竞态就是用-race参数可以看到是否存在资源竞争，用锁可以隔离
* * 局部变量会放在栈上，函数结束后其作用域就结束了，但是如果在函数运行结束后还想用，就叫内存逃逸，Go会分析是否函数结束后还用，如果还用就放到堆上，就叫内存逃逸
* * 如果函数外部存在引用，那么就肯定放堆里，栈放不下也放堆里
* * 内存逃逸的场景，内存逃逸在编译阶段完成
* * 返回对象的指针引用
* * 栈放不下了
* * 变量大小在编译的时候无法确定
* * interface表示不同的类型，就会逃逸
* * 闭包引用对象
* Golang传参
* * 是值传递，不过map、slice、chan、interface都是默认以引用的方式i传递
* * 但是如果map、slice重新改变了内存位置，那就没法改变原来的了
* 空struct{}不占空间，rune是UTF-8字符，相当于int32
* Golang对齐，32位4字节，64位8字节
* * 结构体成员变量偏移量必须是成员大小整数倍
* * 整个结构体地址必须是最大字节的整数倍
* Go设计模式
* * 好多啊，也不太会

### C++
* 智能指针是什么，为什么要智能指针
* shared_ptr, weak_ptr，unique_ptr
* 虚函数的实现方式，虚函数表
* 面向对象的三大特性
* 构造函数和析构函数可以是虚函数吗？为什么？
* C++11的新特性：移动语义，Lambda表达式
* const define static的区别，加在不同位置的作用（比如说成员函数上，可以改变成员属性吗）
* 类模板
* C++类访问权限修饰符以及公有继承保护继承私有继承的区别。
* STL：vector、list、map、set
* vector扩容
* hashmap，unordered_map
* sort底层
* 什么情况下回出现栈、堆内存溢出
* malloc最多能申请多少内存
* 手写memcpy

### 项目
* 6.824 mapreduce是怎么实现节点同步的
* Apache POI内存溢出的解决方法
* 内存溢出的解决方法
* 多个用户向服务器发送多个请求，如何知道他们是哪个用户发送的
* 需要不同版本的第三方包如何处理
* 想要保护数据隐私，在出现异常或者错误时，服务端如何避免将数据隐私泄露给用户
* 大量服务向redis拿缓存的解决办法
* redis加锁如果业务操作过长怎么办
* 秒杀系统设计
* 低代码工具
* 一个tomcat启动，从操作系统的角度分析，它干了什么
* 字符流和字节流的区别，哪些文件适合字符流，哪些适合字节流，字节流可以读取文本文件么，那为什么要用字符流
* 削峰、限流、令牌桶、

### 其他
* 设计模式
* git常用命令
* docker的理解，docker和虚拟机的区别
* docker底层资源隔离
* 大文件，求数字（单词）交集（是否排序）
* 大文件，求出现最多的单词（数字）
* 大文件，求最大的1000个数
* nacos服务发现原理（服务注册+内置dns解析）
* 微服务健康监测怎么实现
* 排序算法：哪些是稳定的
